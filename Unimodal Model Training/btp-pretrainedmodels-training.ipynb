{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MERGING OF CONTEXT AND UTTERANCE FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T15:03:22.827918Z",
     "iopub.status.busy": "2025-03-12T15:03:22.827722Z",
     "iopub.status.idle": "2025-03-12T15:03:25.358205Z",
     "shell.execute_reply": "2025-03-12T15:03:25.357184Z",
     "shell.execute_reply.started": "2025-03-12T15:03:22.827900Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged dataset saved as final_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "MERGING THE AUDIO EMBEDDINGS OF CONTEXT AND UTTERNACE WITH LABELS AND OTHER FEATURES\n",
    "MERGING Wav2Vec2 Embeddings\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the CSV files\n",
    "csv1 = pd.read_csv(\"/kaggle/input/btp-audioembeddings/audio_context_Wav2Vec2_base_embeddings.csv\")\n",
    "csv2 = pd.read_csv(\"/kaggle/input/btp-audioembeddings/audio_utterance_Wav2Vec2_base_embeddings.csv\")\n",
    "map_df = pd.read_csv(\"/kaggle/input/btp-audioembeddings/context_to_utterance_map.csv\")\n",
    "\n",
    "# Remove the 'audio_context/' and 'audio_utterance/' prefixes from map.csv\n",
    "map_df[\"audio_context\"] = map_df[\"audio_context\"].str.replace(\"audio_context/\", \"\", regex=False)\n",
    "map_df[\"audio_utterance\"] = map_df[\"audio_utterance\"].str.replace(\"audio_utterance/\", \"\", regex=False)\n",
    "\n",
    "# Extract features (excluding the first column which is file_name)\n",
    "features_csv1 = csv1.iloc[:, 1:].copy()  # Features from csv1\n",
    "features_csv2 = csv2.iloc[:, 1:].copy()  # Features from csv2\n",
    "\n",
    "# Rename columns to distinguish between csv1 and csv2 features\n",
    "features_csv1.columns = [f\"audio_c_feature_{col}\" for col in features_csv1.columns]\n",
    "features_csv2.columns = [f\"audio_u_feature_{col}\" for col in features_csv2.columns]\n",
    "\n",
    "# Add file_name back to features for merging\n",
    "features_csv1.insert(0, \"filename\", csv1.iloc[:, 0])\n",
    "features_csv2.insert(0, \"filename\", csv2.iloc[:, 0])\n",
    "\n",
    "# Merge csv1 with map.csv using audio_context (which is file_name in csv1)\n",
    "merged_df = map_df.merge(features_csv1, left_on=\"audio_context\", right_on=\"filename\", how=\"inner\")\n",
    "\n",
    "# Merge csv2 with the updated dataframe using audio_utterance (which is file_name in csv2)\n",
    "merged_df = merged_df.merge(features_csv2, left_on=\"audio_utterance\", right_on=\"filename\", how=\"inner\", suffixes=(\"_csv1\", \"_csv2\"))\n",
    "\n",
    "# Drop redundant filename columns from csv1 and csv2\n",
    "merged_df.drop(columns=[\"filename_csv1\", \"filename_csv2\"], inplace=True)\n",
    "\n",
    "# Rename columns to keep them organized\n",
    "#merged_df.rename(columns={\"audio_context\": \"file_csv1\", \"audio_utterance\": \"file_csv2\"}, inplace=True)\n",
    "\n",
    "# Save the final dataset\n",
    "merged_df.to_csv(\"audio_features_Wav2Vec2_base.csv\", index=False)\n",
    "\n",
    "print(\"Merged dataset saved as final_dataset.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Trained On WavLM EMBEDDINGS\n",
    "\n",
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-21T05:32:44.342595Z",
     "iopub.status.busy": "2025-03-21T05:32:44.342211Z",
     "iopub.status.idle": "2025-03-21T05:33:03.556543Z",
     "shell.execute_reply": "2025-03-21T05:33:03.555546Z",
     "shell.execute_reply.started": "2025-03-21T05:32:44.342568Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_6             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ input_layer_7             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ reshape_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ reshape_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv1d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">766</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">504</span> │ reshape_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv1d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">766</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">504</span> │ reshape_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ max_pooling1d_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">383</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)            │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ max_pooling1d_7           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">383</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)            │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ flatten_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48258</span>)          │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ flatten_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48258</span>)          │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ concatenate_3             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96516</span>)          │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ flatten_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,088,544</span> │ concatenate_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │ dense_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_6             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ input_layer_7             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ reshape_6 (\u001b[38;5;33mReshape\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ input_layer_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ reshape_7 (\u001b[38;5;33mReshape\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ input_layer_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv1d_6 (\u001b[38;5;33mConv1D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m766\u001b[0m, \u001b[38;5;34m126\u001b[0m)       │            \u001b[38;5;34m504\u001b[0m │ reshape_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv1d_7 (\u001b[38;5;33mConv1D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m766\u001b[0m, \u001b[38;5;34m126\u001b[0m)       │            \u001b[38;5;34m504\u001b[0m │ reshape_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ max_pooling1d_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m383\u001b[0m, \u001b[38;5;34m126\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ conv1d_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)            │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ max_pooling1d_7           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m383\u001b[0m, \u001b[38;5;34m126\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ conv1d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)            │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ flatten_6 (\u001b[38;5;33mFlatten\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48258\u001b[0m)          │              \u001b[38;5;34m0\u001b[0m │ max_pooling1d_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ flatten_7 (\u001b[38;5;33mFlatten\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48258\u001b[0m)          │              \u001b[38;5;34m0\u001b[0m │ max_pooling1d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ concatenate_3             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96516\u001b[0m)          │              \u001b[38;5;34m0\u001b[0m │ flatten_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ flatten_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │      \u001b[38;5;34m3,088,544\u001b[0m │ concatenate_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m33\u001b[0m │ dense_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,089,585</span> (11.79 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,089,585\u001b[0m (11.79 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,089,585</span> (11.79 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,089,585\u001b[0m (11.79 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5455 - loss: 1.0161\n",
      "Epoch 1: val_accuracy improved from -inf to 0.55833, saving model to /kaggle/working/wav_lm_base_cnn_model.weights.h5\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step - accuracy: 0.5470 - loss: 1.0105 - val_accuracy: 0.5583 - val_loss: 0.7093\n",
      "Epoch 2/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6418 - loss: 0.6028\n",
      "Epoch 2: val_accuracy improved from 0.55833 to 0.56667, saving model to /kaggle/working/wav_lm_base_cnn_model.weights.h5\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6513 - loss: 0.5993 - val_accuracy: 0.5667 - val_loss: 0.6697\n",
      "Epoch 3/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7400 - loss: 0.5296\n",
      "Epoch 3: val_accuracy improved from 0.56667 to 0.64167, saving model to /kaggle/working/wav_lm_base_cnn_model.weights.h5\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7368 - loss: 0.5322 - val_accuracy: 0.6417 - val_loss: 0.6528\n",
      "Epoch 4/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7463 - loss: 0.5080\n",
      "Epoch 4: val_accuracy did not improve from 0.64167\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7455 - loss: 0.5078 - val_accuracy: 0.6000 - val_loss: 0.6611\n",
      "Epoch 5/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8201 - loss: 0.4505\n",
      "Epoch 5: val_accuracy did not improve from 0.64167\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8164 - loss: 0.4506 - val_accuracy: 0.6417 - val_loss: 0.6912\n",
      "Epoch 6/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7853 - loss: 0.4645\n",
      "Epoch 6: val_accuracy did not improve from 0.64167\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7850 - loss: 0.4639 - val_accuracy: 0.6333 - val_loss: 0.7162\n",
      "Epoch 7/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8008 - loss: 0.4305\n",
      "Epoch 7: val_accuracy improved from 0.64167 to 0.65000, saving model to /kaggle/working/wav_lm_base_cnn_model.weights.h5\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8045 - loss: 0.4247 - val_accuracy: 0.6500 - val_loss: 0.7098\n",
      "Epoch 8/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8340 - loss: 0.3839\n",
      "Epoch 8: val_accuracy improved from 0.65000 to 0.66667, saving model to /kaggle/working/wav_lm_base_cnn_model.weights.h5\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8292 - loss: 0.3882 - val_accuracy: 0.6667 - val_loss: 0.7357\n",
      "Epoch 9/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8658 - loss: 0.3501\n",
      "Epoch 9: val_accuracy did not improve from 0.66667\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8640 - loss: 0.3504 - val_accuracy: 0.6583 - val_loss: 0.7443\n",
      "Epoch 10/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8953 - loss: 0.2777\n",
      "Epoch 10: val_accuracy did not improve from 0.66667\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8907 - loss: 0.2823 - val_accuracy: 0.6583 - val_loss: 0.7733\n",
      "Epoch 11/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8916 - loss: 0.2710\n",
      "Epoch 11: val_accuracy did not improve from 0.66667\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8929 - loss: 0.2694 - val_accuracy: 0.6583 - val_loss: 0.7790\n",
      "Epoch 12/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9177 - loss: 0.2246\n",
      "Epoch 12: val_accuracy did not improve from 0.66667\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9162 - loss: 0.2283 - val_accuracy: 0.6667 - val_loss: 0.8057\n",
      "Epoch 13/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9123 - loss: 0.2184\n",
      "Epoch 13: val_accuracy improved from 0.66667 to 0.70833, saving model to /kaggle/working/wav_lm_base_cnn_model.weights.h5\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9096 - loss: 0.2250 - val_accuracy: 0.7083 - val_loss: 0.9124\n",
      "Epoch 14/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9221 - loss: 0.2126\n",
      "Epoch 14: val_accuracy did not improve from 0.70833\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9266 - loss: 0.2073 - val_accuracy: 0.6750 - val_loss: 0.8903\n",
      "Epoch 15/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9532 - loss: 0.1656\n",
      "Epoch 15: val_accuracy did not improve from 0.70833\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9525 - loss: 0.1653 - val_accuracy: 0.6583 - val_loss: 0.9833\n",
      "Epoch 16/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9418 - loss: 0.1597\n",
      "Epoch 16: val_accuracy did not improve from 0.70833\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9407 - loss: 0.1603 - val_accuracy: 0.6583 - val_loss: 1.0081\n",
      "Epoch 17/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9378 - loss: 0.1606\n",
      "Epoch 17: val_accuracy did not improve from 0.70833\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9368 - loss: 0.1592 - val_accuracy: 0.7000 - val_loss: 0.9441\n",
      "Epoch 18/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9695 - loss: 0.1156\n",
      "Epoch 18: val_accuracy did not improve from 0.70833\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9709 - loss: 0.1145 - val_accuracy: 0.6667 - val_loss: 1.1230\n",
      "Epoch 19/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9777 - loss: 0.0935\n",
      "Epoch 19: val_accuracy did not improve from 0.70833\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9787 - loss: 0.0911 - val_accuracy: 0.6250 - val_loss: 1.1726\n",
      "Epoch 20/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9766 - loss: 0.0882\n",
      "Epoch 20: val_accuracy did not improve from 0.70833\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9761 - loss: 0.0888 - val_accuracy: 0.6750 - val_loss: 1.0660\n",
      "Epoch 21/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9854 - loss: 0.0709\n",
      "Epoch 21: val_accuracy did not improve from 0.70833\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9861 - loss: 0.0700 - val_accuracy: 0.6917 - val_loss: 1.0834\n",
      "Epoch 22/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9960 - loss: 0.0455\n",
      "Epoch 22: val_accuracy did not improve from 0.70833\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9963 - loss: 0.0456 - val_accuracy: 0.6917 - val_loss: 1.1339\n",
      "Epoch 23/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9994 - loss: 0.0360\n",
      "Epoch 23: val_accuracy did not improve from 0.70833\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9991 - loss: 0.0366 - val_accuracy: 0.6833 - val_loss: 1.1685\n",
      "Epoch 24/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9920 - loss: 0.0496\n",
      "Epoch 24: val_accuracy did not improve from 0.70833\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9924 - loss: 0.0491 - val_accuracy: 0.6500 - val_loss: 1.3564\n",
      "Epoch 25/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9684 - loss: 0.1000\n",
      "Epoch 25: val_accuracy did not improve from 0.70833\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9713 - loss: 0.0947 - val_accuracy: 0.7083 - val_loss: 1.1600\n",
      "Epoch 26/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0348\n",
      "Epoch 26: val_accuracy did not improve from 0.70833\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0340 - val_accuracy: 0.6500 - val_loss: 1.4565\n",
      "Epoch 27/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9857 - loss: 0.0512\n",
      "Epoch 27: val_accuracy did not improve from 0.70833\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9869 - loss: 0.0487 - val_accuracy: 0.6917 - val_loss: 1.2923\n",
      "Epoch 28/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9992 - loss: 0.0203\n",
      "Epoch 28: val_accuracy did not improve from 0.70833\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9991 - loss: 0.0202 - val_accuracy: 0.6750 - val_loss: 1.2937\n",
      "Epoch 29/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0138\n",
      "Epoch 29: val_accuracy did not improve from 0.70833\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0138 - val_accuracy: 0.6917 - val_loss: 1.2937\n",
      "Epoch 30/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0112\n",
      "Epoch 30: val_accuracy did not improve from 0.70833\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0113 - val_accuracy: 0.6917 - val_loss: 1.3250\n",
      "Epoch 31/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0101\n",
      "Epoch 31: val_accuracy did not improve from 0.70833\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0102 - val_accuracy: 0.6667 - val_loss: 1.3606\n",
      "Epoch 32/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0089\n",
      "Epoch 32: val_accuracy did not improve from 0.70833\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0089 - val_accuracy: 0.7000 - val_loss: 1.3341\n",
      "Epoch 33/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0080\n",
      "Epoch 33: val_accuracy did not improve from 0.70833\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0080 - val_accuracy: 0.7000 - val_loss: 1.3614\n",
      "Epoch 34/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0069\n",
      "Epoch 34: val_accuracy did not improve from 0.70833\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0070 - val_accuracy: 0.6917 - val_loss: 1.3933\n",
      "Epoch 35/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0061\n",
      "Epoch 35: val_accuracy did not improve from 0.70833\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0063 - val_accuracy: 0.7083 - val_loss: 1.4219\n",
      "Epoch 36/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0063\n",
      "Epoch 36: val_accuracy did not improve from 0.70833\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0063 - val_accuracy: 0.6667 - val_loss: 1.4375\n",
      "Epoch 37/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0060\n",
      "Epoch 37: val_accuracy did not improve from 0.70833\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0060 - val_accuracy: 0.6833 - val_loss: 1.4223\n",
      "Epoch 38/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0058\n",
      "Epoch 38: val_accuracy did not improve from 0.70833\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0057 - val_accuracy: 0.7000 - val_loss: 1.4469\n",
      "Epoch 39/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0053\n",
      "Epoch 39: val_accuracy did not improve from 0.70833\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0052 - val_accuracy: 0.7000 - val_loss: 1.4711\n",
      "Epoch 40/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0052\n",
      "Epoch 40: val_accuracy did not improve from 0.70833\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0050 - val_accuracy: 0.7000 - val_loss: 1.4884\n",
      "Epoch 41/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0039\n",
      "Epoch 41: val_accuracy did not improve from 0.70833\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0040 - val_accuracy: 0.7000 - val_loss: 1.4822\n",
      "Epoch 42/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0038\n",
      "Epoch 42: val_accuracy did not improve from 0.70833\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 0.7000 - val_loss: 1.4885\n",
      "Epoch 43/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0039\n",
      "Epoch 43: val_accuracy did not improve from 0.70833\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 0.6833 - val_loss: 1.5223\n",
      "Epoch 44/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0039\n",
      "Epoch 44: val_accuracy did not improve from 0.70833\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 0.7000 - val_loss: 1.5192\n",
      "Epoch 45/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0036\n",
      "Epoch 45: val_accuracy did not improve from 0.70833\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 0.6917 - val_loss: 1.5390\n",
      "Epoch 46/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0032\n",
      "Epoch 46: val_accuracy did not improve from 0.70833\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 0.7000 - val_loss: 1.5522\n",
      "Epoch 47/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0032\n",
      "Epoch 47: val_accuracy did not improve from 0.70833\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.7000 - val_loss: 1.5476\n",
      "Epoch 48/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0029\n",
      "Epoch 48: val_accuracy did not improve from 0.70833\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 0.6917 - val_loss: 1.5717\n",
      "Epoch 49/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0025\n",
      "Epoch 49: val_accuracy did not improve from 0.70833\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.6917 - val_loss: 1.5730\n",
      "Epoch 50/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0026\n",
      "Epoch 50: val_accuracy did not improve from 0.70833\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.7000 - val_loss: 1.5744\n",
      "Loaded Best Model Weights.\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Train Set Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9131    0.9762    0.9436       420\n",
      "         1.0     0.9745    0.9074    0.9397       421\n",
      "\n",
      "    accuracy                         0.9417       841\n",
      "   macro avg     0.9438    0.9418    0.9417       841\n",
      "weighted avg     0.9439    0.9417    0.9417       841\n",
      "\n",
      "Validation Set Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6712    0.8167    0.7368        60\n",
      "         1.0     0.7660    0.6000    0.6729        60\n",
      "\n",
      "    accuracy                         0.7083       120\n",
      "   macro avg     0.7186    0.7083    0.7049       120\n",
      "weighted avg     0.7186    0.7083    0.7049       120\n",
      "\n",
      "Test Set Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6642    0.7521    0.7054       121\n",
      "         1.0     0.7115    0.6167    0.6607       120\n",
      "\n",
      "    accuracy                         0.6846       241\n",
      "   macro avg     0.6879    0.6844    0.6831       241\n",
      "weighted avg     0.6878    0.6846    0.6832       241\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "CNN MODEL\n",
    "\"\"\"\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Load the final dataset\n",
    "df = pd.read_csv(\"/kaggle/input/btp-audioembeddings/audio_features_WavLM_base.csv\")\n",
    "\n",
    "# Extract labels\n",
    "y = df[\"Sarcasm\"].values  # Labels (0: No sarcasm, 1: Sarcasm)\n",
    "\n",
    "# Extract context features (from csv1_)\n",
    "X_context = df[[col for col in df.columns if col.startswith(\"audio_c_feature_\")]].values\n",
    "\n",
    "# Extract utterance features (from csv2_)\n",
    "X_utterance = df[[col for col in df.columns if col.startswith(\"audio_u_feature_\")]].values\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "X_context = np.array(X_context, dtype=np.float32)\n",
    "X_utterance = np.array(X_utterance, dtype=np.float32)\n",
    "y = np.array(y, dtype=np.float32)\n",
    "\n",
    "# First, split into train (70%) and temp (30%) \n",
    "Xc_train, Xc_temp, Xu_train, Xu_temp, y_train, y_temp = train_test_split(\n",
    "    X_context, X_utterance, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Split temp (30%) into validation (10%) and test (20%)\n",
    "Xc_val, Xc_test, Xu_val, Xu_test, y_val, y_test = train_test_split(\n",
    "    Xc_temp, Xu_temp, y_temp, test_size=2/3, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "# CNN Model for Sarcasm Detection\n",
    "input_dim = 768  # Number of features per input\n",
    "\n",
    "# Context Branch\n",
    "input_context = keras.Input(shape=(input_dim,))\n",
    "context_branch = layers.Reshape((input_dim, 1))(input_context)\n",
    "context_branch = layers.Conv1D(filters=126, kernel_size=3, activation=\"tanh\")(context_branch)\n",
    "context_branch = layers.MaxPooling1D(pool_size=2)(context_branch)\n",
    "context_branch = layers.Flatten()(context_branch)\n",
    "\n",
    "# Utterance Branch\n",
    "input_utterance = keras.Input(shape=(input_dim,))\n",
    "utterance_branch = layers.Reshape((input_dim, 1))(input_utterance)\n",
    "utterance_branch = layers.Conv1D(filters=126, kernel_size=3, activation=\"tanh\")(utterance_branch)\n",
    "utterance_branch = layers.MaxPooling1D(pool_size=2)(utterance_branch)\n",
    "utterance_branch = layers.Flatten()(utterance_branch)\n",
    "\n",
    "# Concatenation\n",
    "merged = layers.Concatenate()([context_branch, utterance_branch])\n",
    "merged = layers.Dense(32, activation=\"tanh\")(merged)\n",
    "#merged = layers.Dense(32, activation=\"relu\")(merged)\n",
    "output = layers.Dense(1, activation=\"sigmoid\")(merged)  # Sigmoid for binary classification\n",
    "\n",
    "# Define Model\n",
    "model = keras.Model(inputs=[input_context, input_utterance], outputs=output)\n",
    "model.summary()\n",
    "\n",
    "# Compile Model\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Checkpoint to save the best model based on validation accuracy\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    \"/kaggle/working/wav_lm_base_cnn_model.weights.h5\",\n",
    "    monitor=\"val_accuracy\",  # Monitor validation accuracy\n",
    "    mode=\"max\",  # Save when val_accuracy is maximum\n",
    "    save_best_only=True,  # Keep only the best weights\n",
    "    save_weights_only=True,  # Don't save full model\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train Model\n",
    "model.fit(\n",
    "    [Xc_train, Xu_train], y_train,\n",
    "    epochs=50, batch_size=32,\n",
    "    validation_data=([Xc_val, Xu_val], y_val),  # Use validation set\n",
    "    callbacks=[checkpoint_callback]\n",
    ")\n",
    "\n",
    "# Load best model weights\n",
    "model.load_weights(\"/kaggle/working/wav_lm_base_cnn_model.weights.h5\")\n",
    "print(\"Loaded Best Model Weights.\")\n",
    "\n",
    "# Generate predictions using the best model\n",
    "y_train_pred = (model.predict([Xc_train, Xu_train]) > 0.5).astype(int)\n",
    "y_val_pred = (model.predict([Xc_val, Xu_val]) > 0.5).astype(int)\n",
    "y_test_pred = (model.predict([Xc_test, Xu_test]) > 0.5).astype(int)\n",
    "\n",
    "# Print classification reports for all sets\n",
    "print(\"Train Set Classification Report:\\n\", classification_report(y_train, y_train_pred,digits=4))\n",
    "print(\"Validation Set Classification Report:\\n\", classification_report(y_val, y_val_pred,digits=4))\n",
    "print(\"Test Set Classification Report:\\n\", classification_report(y_test, y_test_pred,digits=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-21T05:41:10.399311Z",
     "iopub.status.busy": "2025-03-21T05:41:10.398919Z",
     "iopub.status.idle": "2025-03-21T05:41:21.407846Z",
     "shell.execute_reply": "2025-03-21T05:41:21.406910Z",
     "shell.execute_reply.started": "2025-03-21T05:41:10.399280Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_8             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ input_layer_9             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">196,864</span> │ input_layer_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">196,864</span> │ input_layer_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ dense_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ dense_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ concatenate_4             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],         │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ dense_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> │ concatenate_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ dense_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_8             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ input_layer_9             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m196,864\u001b[0m │ input_layer_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m196,864\u001b[0m │ input_layer_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m32,896\u001b[0m │ dense_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m32,896\u001b[0m │ dense_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ concatenate_4             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ dense_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],         │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ dense_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m16,448\u001b[0m │ concatenate_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m65\u001b[0m │ dense_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">476,033</span> (1.82 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m476,033\u001b[0m (1.82 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">476,033</span> (1.82 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m476,033\u001b[0m (1.82 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5385 - loss: 0.7904\n",
      "Epoch 1: val_accuracy improved from -inf to 0.56667, saving model to /kaggle/working/wav_lm_base_fcn_model.weights.h5\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - accuracy: 0.5394 - loss: 0.7888 - val_accuracy: 0.5667 - val_loss: 0.6870\n",
      "Epoch 2/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8750 - loss: 0.5142\n",
      "Epoch 2: val_accuracy improved from 0.56667 to 0.59167, saving model to /kaggle/working/wav_lm_base_fcn_model.weights.h5\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6384 - loss: 0.6417 - val_accuracy: 0.5917 - val_loss: 0.7036\n",
      "Epoch 3/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7812 - loss: 0.4878\n",
      "Epoch 3: val_accuracy did not improve from 0.59167\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6836 - loss: 0.5798 - val_accuracy: 0.5917 - val_loss: 0.8207\n",
      "Epoch 4/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6875 - loss: 0.4710\n",
      "Epoch 4: val_accuracy improved from 0.59167 to 0.60833, saving model to /kaggle/working/wav_lm_base_fcn_model.weights.h5\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6640 - loss: 0.6111 - val_accuracy: 0.6083 - val_loss: 0.6831\n",
      "Epoch 5/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7500 - loss: 0.4556\n",
      "Epoch 5: val_accuracy did not improve from 0.60833\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7310 - loss: 0.5190 - val_accuracy: 0.5667 - val_loss: 0.8019\n",
      "Epoch 6/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7500 - loss: 0.4898\n",
      "Epoch 6: val_accuracy improved from 0.60833 to 0.64167, saving model to /kaggle/working/wav_lm_base_fcn_model.weights.h5\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7642 - loss: 0.5079 - val_accuracy: 0.6417 - val_loss: 0.7538\n",
      "Epoch 7/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8438 - loss: 0.4241\n",
      "Epoch 7: val_accuracy improved from 0.64167 to 0.66667, saving model to /kaggle/working/wav_lm_base_fcn_model.weights.h5\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7724 - loss: 0.4579 - val_accuracy: 0.6667 - val_loss: 0.7268\n",
      "Epoch 8/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7188 - loss: 0.5251\n",
      "Epoch 8: val_accuracy did not improve from 0.66667\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7831 - loss: 0.4322 - val_accuracy: 0.5417 - val_loss: 0.7616\n",
      "Epoch 9/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7500 - loss: 0.4893\n",
      "Epoch 9: val_accuracy did not improve from 0.66667\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7907 - loss: 0.4511 - val_accuracy: 0.6167 - val_loss: 0.7724\n",
      "Epoch 10/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8750 - loss: 0.3135\n",
      "Epoch 10: val_accuracy did not improve from 0.66667\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8215 - loss: 0.3858 - val_accuracy: 0.6167 - val_loss: 0.7593\n",
      "Epoch 11/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7812 - loss: 0.4668\n",
      "Epoch 11: val_accuracy did not improve from 0.66667\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7873 - loss: 0.4361 - val_accuracy: 0.6167 - val_loss: 0.8353\n",
      "Epoch 12/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9688 - loss: 0.2626\n",
      "Epoch 12: val_accuracy did not improve from 0.66667\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8852 - loss: 0.3105 - val_accuracy: 0.5833 - val_loss: 0.9149\n",
      "Epoch 13/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8438 - loss: 0.2943\n",
      "Epoch 13: val_accuracy did not improve from 0.66667\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8842 - loss: 0.2744 - val_accuracy: 0.6167 - val_loss: 0.8913\n",
      "Epoch 14/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9062 - loss: 0.2621\n",
      "Epoch 14: val_accuracy did not improve from 0.66667\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8990 - loss: 0.2564 - val_accuracy: 0.6000 - val_loss: 1.1084\n",
      "Epoch 15/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9375 - loss: 0.1592\n",
      "Epoch 15: val_accuracy did not improve from 0.66667\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8918 - loss: 0.2509 - val_accuracy: 0.6167 - val_loss: 0.9730\n",
      "Epoch 16/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9688 - loss: 0.1408\n",
      "Epoch 16: val_accuracy did not improve from 0.66667\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9316 - loss: 0.1953 - val_accuracy: 0.5833 - val_loss: 0.9571\n",
      "Epoch 17/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9375 - loss: 0.1505\n",
      "Epoch 17: val_accuracy did not improve from 0.66667\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8819 - loss: 0.2832 - val_accuracy: 0.6000 - val_loss: 0.9499\n",
      "Epoch 18/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8750 - loss: 0.2559\n",
      "Epoch 18: val_accuracy did not improve from 0.66667\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9317 - loss: 0.1881 - val_accuracy: 0.6167 - val_loss: 1.0806\n",
      "Epoch 19/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8750 - loss: 0.1914\n",
      "Epoch 19: val_accuracy did not improve from 0.66667\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9427 - loss: 0.1522 - val_accuracy: 0.6000 - val_loss: 1.1306\n",
      "Epoch 20/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9375 - loss: 0.1739\n",
      "Epoch 20: val_accuracy did not improve from 0.66667\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9498 - loss: 0.1525 - val_accuracy: 0.6417 - val_loss: 1.1353\n",
      "Epoch 21/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9375 - loss: 0.0857\n",
      "Epoch 21: val_accuracy did not improve from 0.66667\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9580 - loss: 0.1199 - val_accuracy: 0.6333 - val_loss: 1.1840\n",
      "Epoch 22/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0884\n",
      "Epoch 22: val_accuracy did not improve from 0.66667\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9665 - loss: 0.1227 - val_accuracy: 0.6417 - val_loss: 1.3013\n",
      "Epoch 23/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9688 - loss: 0.1050\n",
      "Epoch 23: val_accuracy did not improve from 0.66667\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9523 - loss: 0.1380 - val_accuracy: 0.6417 - val_loss: 1.1470\n",
      "Epoch 24/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0884\n",
      "Epoch 24: val_accuracy did not improve from 0.66667\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9783 - loss: 0.0905 - val_accuracy: 0.6417 - val_loss: 1.1237\n",
      "Epoch 25/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0990\n",
      "Epoch 25: val_accuracy did not improve from 0.66667\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9780 - loss: 0.0992 - val_accuracy: 0.6417 - val_loss: 1.2868\n",
      "Epoch 26/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9688 - loss: 0.0624\n",
      "Epoch 26: val_accuracy did not improve from 0.66667\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9826 - loss: 0.0782 - val_accuracy: 0.6500 - val_loss: 1.1761\n",
      "Epoch 27/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9688 - loss: 0.0662\n",
      "Epoch 27: val_accuracy did not improve from 0.66667\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9844 - loss: 0.0690 - val_accuracy: 0.6417 - val_loss: 1.3466\n",
      "Epoch 28/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0420\n",
      "Epoch 28: val_accuracy did not improve from 0.66667\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9981 - loss: 0.0391 - val_accuracy: 0.6333 - val_loss: 1.3787\n",
      "Epoch 29/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0257\n",
      "Epoch 29: val_accuracy did not improve from 0.66667\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0342 - val_accuracy: 0.6250 - val_loss: 1.4684\n",
      "Epoch 30/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0265\n",
      "Epoch 30: val_accuracy did not improve from 0.66667\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0285 - val_accuracy: 0.6083 - val_loss: 1.4938\n",
      "Epoch 31/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0199\n",
      "Epoch 31: val_accuracy did not improve from 0.66667\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0223 - val_accuracy: 0.6250 - val_loss: 1.4639\n",
      "Epoch 32/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0119\n",
      "Epoch 32: val_accuracy did not improve from 0.66667\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0162 - val_accuracy: 0.6167 - val_loss: 1.5244\n",
      "Epoch 33/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0177\n",
      "Epoch 33: val_accuracy did not improve from 0.66667\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0166 - val_accuracy: 0.6167 - val_loss: 1.7471\n",
      "Epoch 34/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0070\n",
      "Epoch 34: val_accuracy did not improve from 0.66667\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9982 - loss: 0.0227 - val_accuracy: 0.6083 - val_loss: 1.6120\n",
      "Epoch 35/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0158\n",
      "Epoch 35: val_accuracy did not improve from 0.66667\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9729 - loss: 0.0692 - val_accuracy: 0.6000 - val_loss: 1.4571\n",
      "Epoch 36/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0293\n",
      "Epoch 36: val_accuracy did not improve from 0.66667\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9922 - loss: 0.0430 - val_accuracy: 0.6167 - val_loss: 1.4584\n",
      "Epoch 37/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9688 - loss: 0.0824\n",
      "Epoch 37: val_accuracy did not improve from 0.66667\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9623 - loss: 0.0989 - val_accuracy: 0.6000 - val_loss: 1.5552\n",
      "Epoch 38/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0407\n",
      "Epoch 38: val_accuracy did not improve from 0.66667\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9651 - loss: 0.0917 - val_accuracy: 0.6083 - val_loss: 1.5705\n",
      "Epoch 39/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0340\n",
      "Epoch 39: val_accuracy did not improve from 0.66667\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9985 - loss: 0.0265 - val_accuracy: 0.6083 - val_loss: 1.4562\n",
      "Epoch 40/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0111\n",
      "Epoch 40: val_accuracy did not improve from 0.66667\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0156 - val_accuracy: 0.6167 - val_loss: 1.5957\n",
      "Epoch 41/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0076\n",
      "Epoch 41: val_accuracy did not improve from 0.66667\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0117 - val_accuracy: 0.6333 - val_loss: 1.6656\n",
      "Epoch 42/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0122\n",
      "Epoch 42: val_accuracy did not improve from 0.66667\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0090 - val_accuracy: 0.6083 - val_loss: 1.7514\n",
      "Epoch 43/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.0051\n",
      "Epoch 43: val_accuracy did not improve from 0.66667\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0072 - val_accuracy: 0.6000 - val_loss: 1.7971\n",
      "Epoch 44/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0073\n",
      "Epoch 44: val_accuracy did not improve from 0.66667\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0063 - val_accuracy: 0.6083 - val_loss: 1.7787\n",
      "Epoch 45/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0048\n",
      "Epoch 45: val_accuracy did not improve from 0.66667\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0057 - val_accuracy: 0.6167 - val_loss: 1.7971\n",
      "Epoch 46/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0063\n",
      "Epoch 46: val_accuracy did not improve from 0.66667\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0054 - val_accuracy: 0.6000 - val_loss: 1.8319\n",
      "Epoch 47/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0057\n",
      "Epoch 47: val_accuracy did not improve from 0.66667\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0050 - val_accuracy: 0.6250 - val_loss: 1.8741\n",
      "Epoch 48/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.0069\n",
      "Epoch 48: val_accuracy did not improve from 0.66667\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0052 - val_accuracy: 0.6250 - val_loss: 1.8823\n",
      "Epoch 49/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0045\n",
      "Epoch 49: val_accuracy did not improve from 0.66667\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0041 - val_accuracy: 0.6167 - val_loss: 1.9198\n",
      "Epoch 50/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0030\n",
      "Epoch 50: val_accuracy did not improve from 0.66667\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0040 - val_accuracy: 0.6250 - val_loss: 1.9371\n",
      "Loaded Best Model Weights.\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Train Set Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7322    0.9048    0.8094       420\n",
      "         1.0     0.8758    0.6698    0.7591       421\n",
      "\n",
      "    accuracy                         0.7872       841\n",
      "   macro avg     0.8040    0.7873    0.7842       841\n",
      "weighted avg     0.8041    0.7872    0.7842       841\n",
      "\n",
      "Validation Set Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6351    0.7833    0.7015        60\n",
      "         1.0     0.7174    0.5500    0.6226        60\n",
      "\n",
      "    accuracy                         0.6667       120\n",
      "   macro avg     0.6763    0.6667    0.6621       120\n",
      "weighted avg     0.6763    0.6667    0.6621       120\n",
      "\n",
      "Test Set Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6419    0.7851    0.7063       121\n",
      "         1.0     0.7204    0.5583    0.6291       120\n",
      "\n",
      "    accuracy                         0.6722       241\n",
      "   macro avg     0.6812    0.6717    0.6677       241\n",
      "weighted avg     0.6810    0.6722    0.6679       241\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "FCN MODEL\n",
    "\"\"\"\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Load the final dataset\n",
    "df = pd.read_csv(\"/kaggle/input/btp-audioembeddings/audio_features_WavLM_base.csv\")\n",
    "\n",
    "# Extract labels\n",
    "y = df[\"Sarcasm\"].values  # Labels (0: No sarcasm, 1: Sarcasm)\n",
    "\n",
    "# Extract context and utterance features\n",
    "X_context = df[[col for col in df.columns if col.startswith(\"audio_c_feature_\")]].values\n",
    "X_utterance = df[[col for col in df.columns if col.startswith(\"audio_u_feature_\")]].values\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "X_context = np.array(X_context, dtype=np.float32)\n",
    "X_utterance = np.array(X_utterance, dtype=np.float32)\n",
    "y = np.array(y, dtype=np.float32)\n",
    "\n",
    "# First, split into train (70%) and temp (30%) \n",
    "Xc_train, Xc_temp, Xu_train, Xu_temp, y_train, y_temp = train_test_split(\n",
    "    X_context, X_utterance, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Split temp (30%) into validation (10%) and test (20%)\n",
    "Xc_val, Xc_test, Xu_val, Xu_test, y_val, y_test = train_test_split(\n",
    "    Xc_temp, Xu_temp, y_temp, test_size=2/3, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "# FCN Model for Sarcasm Detection\n",
    "input_dim = 768  # Number of features per input\n",
    "\n",
    "# Context Branch (Fully Connected Layers)\n",
    "input_context = keras.Input(shape=(input_dim,))\n",
    "context_branch = layers.Dense(256, activation=\"tanh\")(input_context)\n",
    "context_branch = layers.Dense(128, activation=\"tanh\")(context_branch)\n",
    "\n",
    "# Utterance Branch (Fully Connected Layers)\n",
    "input_utterance = keras.Input(shape=(input_dim,))\n",
    "utterance_branch = layers.Dense(256, activation=\"tanh\")(input_utterance)\n",
    "utterance_branch = layers.Dense(128, activation=\"tanh\")(utterance_branch)\n",
    "\n",
    "# Concatenation\n",
    "merged = layers.Concatenate()([context_branch, utterance_branch])\n",
    "merged = layers.Dense(64, activation=\"tanh\")(merged)\n",
    "output = layers.Dense(1, activation=\"sigmoid\")(merged)  # Sigmoid for binary classification\n",
    "\n",
    "# Define Model\n",
    "model = keras.Model(inputs=[input_context, input_utterance], outputs=output)\n",
    "model.summary()\n",
    "\n",
    "# Compile Model\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Checkpoint to save the best model based on validation accuracy\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    \"/kaggle/working/wav_lm_base_fcn_model.weights.h5\",\n",
    "    monitor=\"val_accuracy\",\n",
    "    mode=\"max\",\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train Model\n",
    "model.fit(\n",
    "    [Xc_train, Xu_train], y_train,\n",
    "    epochs=50, batch_size=32,\n",
    "    validation_data=([Xc_val, Xu_val], y_val),\n",
    "    callbacks=[checkpoint_callback]\n",
    ")\n",
    "\n",
    "# Load best model weights\n",
    "model.load_weights(\"/kaggle/working/wav_lm_base_fcn_model.weights.h5\")\n",
    "print(\"Loaded Best Model Weights.\")\n",
    "\n",
    "# Generate predictions using the best model\n",
    "y_train_pred = (model.predict([Xc_train, Xu_train]) > 0.5).astype(int)\n",
    "y_val_pred = (model.predict([Xc_val, Xu_val]) > 0.5).astype(int)\n",
    "y_test_pred = (model.predict([Xc_test, Xu_test]) > 0.5).astype(int)\n",
    "\n",
    "# Print classification reports\n",
    "print(\"Train Set Classification Report:\\n\", classification_report(y_train, y_train_pred, digits=4))\n",
    "print(\"Validation Set Classification Report:\\n\", classification_report(y_val, y_val_pred, digits=4))\n",
    "print(\"Test Set Classification Report:\\n\", classification_report(y_test, y_test_pred, digits=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Trained On Wav2Vec2 Embeddings\n",
    "\n",
    "### CNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-21T05:49:38.150150Z",
     "iopub.status.busy": "2025-03-21T05:49:38.149863Z",
     "iopub.status.idle": "2025-03-21T05:49:54.789726Z",
     "shell.execute_reply": "2025-03-21T05:49:54.788800Z",
     "shell.execute_reply.started": "2025-03-21T05:49:38.150128Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_11\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_11\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_22            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ input_layer_23            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ reshape_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ reshape_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv1d_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">766</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">504</span> │ reshape_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv1d_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">766</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">504</span> │ reshape_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ max_pooling1d_20          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">383</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)            │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ max_pooling1d_21          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">383</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)            │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ flatten_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48258</span>)          │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ flatten_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48258</span>)          │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ concatenate_11            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96516</span>)          │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ flatten_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">96,517</span> │ concatenate_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_22            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ input_layer_23            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ reshape_20 (\u001b[38;5;33mReshape\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ input_layer_22[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ reshape_21 (\u001b[38;5;33mReshape\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ input_layer_23[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv1d_20 (\u001b[38;5;33mConv1D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m766\u001b[0m, \u001b[38;5;34m126\u001b[0m)       │            \u001b[38;5;34m504\u001b[0m │ reshape_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv1d_21 (\u001b[38;5;33mConv1D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m766\u001b[0m, \u001b[38;5;34m126\u001b[0m)       │            \u001b[38;5;34m504\u001b[0m │ reshape_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ max_pooling1d_20          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m383\u001b[0m, \u001b[38;5;34m126\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ conv1d_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)            │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ max_pooling1d_21          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m383\u001b[0m, \u001b[38;5;34m126\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ conv1d_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)            │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ flatten_20 (\u001b[38;5;33mFlatten\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48258\u001b[0m)          │              \u001b[38;5;34m0\u001b[0m │ max_pooling1d_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ flatten_21 (\u001b[38;5;33mFlatten\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48258\u001b[0m)          │              \u001b[38;5;34m0\u001b[0m │ max_pooling1d_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ concatenate_11            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96516\u001b[0m)          │              \u001b[38;5;34m0\u001b[0m │ flatten_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ flatten_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_25 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │         \u001b[38;5;34m96,517\u001b[0m │ concatenate_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">97,525</span> (380.96 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m97,525\u001b[0m (380.96 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">97,525</span> (380.96 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m97,525\u001b[0m (380.96 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5786 - loss: 0.7476\n",
      "Epoch 1: val_accuracy improved from -inf to 0.57500, saving model to /kaggle/working/wav2vec2_base_cnn_model.weights.h5\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - accuracy: 0.5794 - loss: 0.7457 - val_accuracy: 0.5750 - val_loss: 0.6458\n",
      "Epoch 2/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6759 - loss: 0.6087\n",
      "Epoch 2: val_accuracy improved from 0.57500 to 0.64167, saving model to /kaggle/working/wav2vec2_base_cnn_model.weights.h5\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6747 - loss: 0.6095 - val_accuracy: 0.6417 - val_loss: 0.6544\n",
      "Epoch 3/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6904 - loss: 0.5932\n",
      "Epoch 3: val_accuracy did not improve from 0.64167\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6896 - loss: 0.5937 - val_accuracy: 0.6000 - val_loss: 0.6319\n",
      "Epoch 4/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6709 - loss: 0.6066\n",
      "Epoch 4: val_accuracy did not improve from 0.64167\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6730 - loss: 0.6052 - val_accuracy: 0.5917 - val_loss: 0.6736\n",
      "Epoch 5/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7173 - loss: 0.5805\n",
      "Epoch 5: val_accuracy improved from 0.64167 to 0.67500, saving model to /kaggle/working/wav2vec2_base_cnn_model.weights.h5\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7163 - loss: 0.5814 - val_accuracy: 0.6750 - val_loss: 0.6292\n",
      "Epoch 6/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7296 - loss: 0.5405\n",
      "Epoch 6: val_accuracy improved from 0.67500 to 0.68333, saving model to /kaggle/working/wav2vec2_base_cnn_model.weights.h5\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7279 - loss: 0.5421 - val_accuracy: 0.6833 - val_loss: 0.6381\n",
      "Epoch 7/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7368 - loss: 0.5297\n",
      "Epoch 7: val_accuracy did not improve from 0.68333\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7370 - loss: 0.5313 - val_accuracy: 0.6667 - val_loss: 0.6589\n",
      "Epoch 8/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7273 - loss: 0.5173\n",
      "Epoch 8: val_accuracy did not improve from 0.68333\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7271 - loss: 0.5180 - val_accuracy: 0.6500 - val_loss: 0.6194\n",
      "Epoch 9/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7375 - loss: 0.5340\n",
      "Epoch 9: val_accuracy did not improve from 0.68333\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7392 - loss: 0.5321 - val_accuracy: 0.6667 - val_loss: 0.6476\n",
      "Epoch 10/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7538 - loss: 0.5053\n",
      "Epoch 10: val_accuracy did not improve from 0.68333\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7535 - loss: 0.5054 - val_accuracy: 0.6250 - val_loss: 0.6525\n",
      "Epoch 11/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7598 - loss: 0.5027\n",
      "Epoch 11: val_accuracy did not improve from 0.68333\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7589 - loss: 0.5034 - val_accuracy: 0.6000 - val_loss: 0.8053\n",
      "Epoch 12/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7041 - loss: 0.5655\n",
      "Epoch 12: val_accuracy did not improve from 0.68333\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7072 - loss: 0.5622 - val_accuracy: 0.6833 - val_loss: 0.6918\n",
      "Epoch 13/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7441 - loss: 0.4785\n",
      "Epoch 13: val_accuracy did not improve from 0.68333\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7462 - loss: 0.4779 - val_accuracy: 0.6667 - val_loss: 0.6597\n",
      "Epoch 14/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8087 - loss: 0.4690\n",
      "Epoch 14: val_accuracy did not improve from 0.68333\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8057 - loss: 0.4698 - val_accuracy: 0.5917 - val_loss: 0.6508\n",
      "Epoch 15/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7633 - loss: 0.4650\n",
      "Epoch 15: val_accuracy did not improve from 0.68333\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7649 - loss: 0.4651 - val_accuracy: 0.6167 - val_loss: 0.7023\n",
      "Epoch 16/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7895 - loss: 0.4382\n",
      "Epoch 16: val_accuracy did not improve from 0.68333\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7889 - loss: 0.4402 - val_accuracy: 0.6000 - val_loss: 0.6815\n",
      "Epoch 17/50\n",
      "\u001b[1m24/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8138 - loss: 0.4212\n",
      "Epoch 17: val_accuracy did not improve from 0.68333\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8120 - loss: 0.4235 - val_accuracy: 0.6500 - val_loss: 0.7587\n",
      "Epoch 18/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7730 - loss: 0.4517\n",
      "Epoch 18: val_accuracy did not improve from 0.68333\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7746 - loss: 0.4503 - val_accuracy: 0.6250 - val_loss: 0.7073\n",
      "Epoch 19/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8314 - loss: 0.3875\n",
      "Epoch 19: val_accuracy did not improve from 0.68333\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8284 - loss: 0.3908 - val_accuracy: 0.6750 - val_loss: 0.7082\n",
      "Epoch 20/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8076 - loss: 0.4092\n",
      "Epoch 20: val_accuracy did not improve from 0.68333\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8071 - loss: 0.4100 - val_accuracy: 0.5833 - val_loss: 0.7701\n",
      "Epoch 21/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8057 - loss: 0.4034\n",
      "Epoch 21: val_accuracy did not improve from 0.68333\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8056 - loss: 0.4041 - val_accuracy: 0.5917 - val_loss: 0.7528\n",
      "Epoch 22/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8212 - loss: 0.3830\n",
      "Epoch 22: val_accuracy did not improve from 0.68333\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8221 - loss: 0.3829 - val_accuracy: 0.6000 - val_loss: 0.7446\n",
      "Epoch 23/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8408 - loss: 0.3614\n",
      "Epoch 23: val_accuracy did not improve from 0.68333\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8395 - loss: 0.3636 - val_accuracy: 0.5833 - val_loss: 0.7111\n",
      "Epoch 24/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8555 - loss: 0.3479\n",
      "Epoch 24: val_accuracy did not improve from 0.68333\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8529 - loss: 0.3515 - val_accuracy: 0.5750 - val_loss: 0.7359\n",
      "Epoch 25/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8613 - loss: 0.3348\n",
      "Epoch 25: val_accuracy did not improve from 0.68333\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8605 - loss: 0.3359 - val_accuracy: 0.6083 - val_loss: 0.8192\n",
      "Epoch 26/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8571 - loss: 0.3540\n",
      "Epoch 26: val_accuracy did not improve from 0.68333\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8563 - loss: 0.3537 - val_accuracy: 0.5667 - val_loss: 0.7633\n",
      "Epoch 27/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8757 - loss: 0.3190\n",
      "Epoch 27: val_accuracy did not improve from 0.68333\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8721 - loss: 0.3242 - val_accuracy: 0.6250 - val_loss: 0.8933\n",
      "Epoch 28/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8322 - loss: 0.3492\n",
      "Epoch 28: val_accuracy did not improve from 0.68333\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8330 - loss: 0.3496 - val_accuracy: 0.5833 - val_loss: 0.8653\n",
      "Epoch 29/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8378 - loss: 0.3458\n",
      "Epoch 29: val_accuracy did not improve from 0.68333\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8400 - loss: 0.3442 - val_accuracy: 0.5833 - val_loss: 0.8073\n",
      "Epoch 30/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9032 - loss: 0.2877\n",
      "Epoch 30: val_accuracy did not improve from 0.68333\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9018 - loss: 0.2883 - val_accuracy: 0.6000 - val_loss: 0.8637\n",
      "Epoch 31/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8417 - loss: 0.3402\n",
      "Epoch 31: val_accuracy did not improve from 0.68333\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8416 - loss: 0.3400 - val_accuracy: 0.5750 - val_loss: 0.8589\n",
      "Epoch 32/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8623 - loss: 0.3240\n",
      "Epoch 32: val_accuracy did not improve from 0.68333\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8641 - loss: 0.3222 - val_accuracy: 0.6417 - val_loss: 0.9203\n",
      "Epoch 33/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8397 - loss: 0.3373\n",
      "Epoch 33: val_accuracy did not improve from 0.68333\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8400 - loss: 0.3367 - val_accuracy: 0.5833 - val_loss: 0.9081\n",
      "Epoch 34/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8412 - loss: 0.3442\n",
      "Epoch 34: val_accuracy did not improve from 0.68333\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8437 - loss: 0.3399 - val_accuracy: 0.6083 - val_loss: 0.8940\n",
      "Epoch 35/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8715 - loss: 0.3107\n",
      "Epoch 35: val_accuracy did not improve from 0.68333\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8727 - loss: 0.3083 - val_accuracy: 0.6000 - val_loss: 0.9631\n",
      "Epoch 36/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9020 - loss: 0.2558\n",
      "Epoch 36: val_accuracy did not improve from 0.68333\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9020 - loss: 0.2566 - val_accuracy: 0.6083 - val_loss: 0.9382\n",
      "Epoch 37/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9177 - loss: 0.2386\n",
      "Epoch 37: val_accuracy did not improve from 0.68333\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9177 - loss: 0.2396 - val_accuracy: 0.5833 - val_loss: 0.8946\n",
      "Epoch 38/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9426 - loss: 0.2337\n",
      "Epoch 38: val_accuracy did not improve from 0.68333\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9408 - loss: 0.2342 - val_accuracy: 0.5833 - val_loss: 0.9511\n",
      "Epoch 39/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9240 - loss: 0.2270\n",
      "Epoch 39: val_accuracy did not improve from 0.68333\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9238 - loss: 0.2271 - val_accuracy: 0.5917 - val_loss: 0.9496\n",
      "Epoch 40/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9383 - loss: 0.2199\n",
      "Epoch 40: val_accuracy did not improve from 0.68333\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9369 - loss: 0.2211 - val_accuracy: 0.6333 - val_loss: 1.0618\n",
      "Epoch 41/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8863 - loss: 0.2593\n",
      "Epoch 41: val_accuracy did not improve from 0.68333\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8888 - loss: 0.2570 - val_accuracy: 0.5917 - val_loss: 0.9347\n",
      "Epoch 42/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9240 - loss: 0.2211\n",
      "Epoch 42: val_accuracy did not improve from 0.68333\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9224 - loss: 0.2226 - val_accuracy: 0.5917 - val_loss: 1.0342\n",
      "Epoch 43/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9040 - loss: 0.2373\n",
      "Epoch 43: val_accuracy did not improve from 0.68333\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9051 - loss: 0.2359 - val_accuracy: 0.5750 - val_loss: 0.9265\n",
      "Epoch 44/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9211 - loss: 0.2195\n",
      "Epoch 44: val_accuracy did not improve from 0.68333\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9201 - loss: 0.2202 - val_accuracy: 0.6250 - val_loss: 1.0546\n",
      "Epoch 45/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9289 - loss: 0.2016\n",
      "Epoch 45: val_accuracy did not improve from 0.68333\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9289 - loss: 0.2012 - val_accuracy: 0.5833 - val_loss: 0.9769\n",
      "Epoch 46/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9496 - loss: 0.1800\n",
      "Epoch 46: val_accuracy did not improve from 0.68333\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9458 - loss: 0.1846 - val_accuracy: 0.5833 - val_loss: 1.0082\n",
      "Epoch 47/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9227 - loss: 0.1966\n",
      "Epoch 47: val_accuracy did not improve from 0.68333\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9227 - loss: 0.1976 - val_accuracy: 0.5833 - val_loss: 0.9859\n",
      "Epoch 48/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9489 - loss: 0.1591\n",
      "Epoch 48: val_accuracy did not improve from 0.68333\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9485 - loss: 0.1600 - val_accuracy: 0.5833 - val_loss: 0.9547\n",
      "Epoch 49/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9590 - loss: 0.1611\n",
      "Epoch 49: val_accuracy did not improve from 0.68333\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9571 - loss: 0.1629 - val_accuracy: 0.5750 - val_loss: 0.9958\n",
      "Epoch 50/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9634 - loss: 0.1473\n",
      "Epoch 50: val_accuracy did not improve from 0.68333\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9621 - loss: 0.1498 - val_accuracy: 0.5833 - val_loss: 1.0996\n",
      "Loaded Best Model Weights.\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Train Set Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7249    0.8095    0.7649       420\n",
      "         1.0     0.7849    0.6936    0.7364       421\n",
      "\n",
      "    accuracy                         0.7515       841\n",
      "   macro avg     0.7549    0.7516    0.7507       841\n",
      "weighted avg     0.7550    0.7515    0.7507       841\n",
      "\n",
      "Validation Set Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6528    0.7833    0.7121        60\n",
      "         1.0     0.7292    0.5833    0.6481        60\n",
      "\n",
      "    accuracy                         0.6833       120\n",
      "   macro avg     0.6910    0.6833    0.6801       120\n",
      "weighted avg     0.6910    0.6833    0.6801       120\n",
      "\n",
      "Test Set Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6903    0.6446    0.6667       121\n",
      "         1.0     0.6641    0.7083    0.6855       120\n",
      "\n",
      "    accuracy                         0.6763       241\n",
      "   macro avg     0.6772    0.6765    0.6761       241\n",
      "weighted avg     0.6772    0.6763    0.6760       241\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "CNN MODEL\n",
    "\"\"\"\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Load the final dataset\n",
    "df = pd.read_csv(\"/kaggle/input/btp-audioembeddings/audio_features_Wav2Vec2_base.csv\")\n",
    "\n",
    "# Extract labels\n",
    "y = df[\"Sarcasm\"].values  # Labels (0: No sarcasm, 1: Sarcasm)\n",
    "\n",
    "# Extract context features (from csv1_)\n",
    "X_context = df[[col for col in df.columns if col.startswith(\"audio_c_feature_\")]].values\n",
    "\n",
    "# Extract utterance features (from csv2_)\n",
    "X_utterance = df[[col for col in df.columns if col.startswith(\"audio_u_feature_\")]].values\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "X_context = np.array(X_context, dtype=np.float32)\n",
    "X_utterance = np.array(X_utterance, dtype=np.float32)\n",
    "y = np.array(y, dtype=np.float32)\n",
    "\n",
    "# First, split into train (70%) and temp (30%) \n",
    "Xc_train, Xc_temp, Xu_train, Xu_temp, y_train, y_temp = train_test_split(\n",
    "    X_context, X_utterance, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Split temp (30%) into validation (10%) and test (20%)\n",
    "Xc_val, Xc_test, Xu_val, Xu_test, y_val, y_test = train_test_split(\n",
    "    Xc_temp, Xu_temp, y_temp, test_size=2/3, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "# CNN Model for Sarcasm Detection\n",
    "input_dim = 768  # Number of features per input\n",
    "\n",
    "# Context Branch\n",
    "input_context = keras.Input(shape=(input_dim,))\n",
    "context_branch = layers.Reshape((input_dim, 1))(input_context)\n",
    "context_branch = layers.Conv1D(filters=126, kernel_size=3, activation=\"tanh\")(context_branch)\n",
    "context_branch = layers.MaxPooling1D(pool_size=2)(context_branch)\n",
    "context_branch = layers.Flatten()(context_branch)\n",
    "\n",
    "# Utterance Branch\n",
    "input_utterance = keras.Input(shape=(input_dim,))\n",
    "utterance_branch = layers.Reshape((input_dim, 1))(input_utterance)\n",
    "utterance_branch = layers.Conv1D(filters=126, kernel_size=3, activation=\"tanh\")(utterance_branch)\n",
    "utterance_branch = layers.MaxPooling1D(pool_size=2)(utterance_branch)\n",
    "utterance_branch = layers.Flatten()(utterance_branch)\n",
    "\n",
    "# Concatenation\n",
    "merged = layers.Concatenate()([context_branch, utterance_branch])#merged = layers.Dense(32, activation=\"relu\")(merged)\n",
    "#merged = layers.Dense(32, activation=\"relu\")(merged)\n",
    "output = layers.Dense(1, activation=\"sigmoid\")(merged)  # Sigmoid for binary classification\n",
    "\n",
    "# Define Model\n",
    "model = keras.Model(inputs=[input_context, input_utterance], outputs=output)\n",
    "model.summary()\n",
    "\n",
    "# Compile Model\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Checkpoint to save the best model based on validation accuracy\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    \"/kaggle/working/wav2vec2_base_cnn_model.weights.h5\",\n",
    "    monitor=\"val_accuracy\",  # Monitor validation accuracy\n",
    "    mode=\"max\",  # Save when val_accuracy is maximum\n",
    "    save_best_only=True,  # Keep only the best weights\n",
    "    save_weights_only=True,  # Don't save full model\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train Model\n",
    "model.fit(\n",
    "    [Xc_train, Xu_train], y_train,\n",
    "    epochs=50, batch_size=32,\n",
    "    validation_data=([Xc_val, Xu_val], y_val),  # Use validation set\n",
    "    callbacks=[checkpoint_callback]\n",
    ")\n",
    "\n",
    "# Load best model weights\n",
    "model.load_weights(\"/kaggle/working/wav2vec2_base_cnn_model.weights.h5\")\n",
    "print(\"Loaded Best Model Weights.\")\n",
    "\n",
    "# Generate predictions using the best model\n",
    "y_train_pred = (model.predict([Xc_train, Xu_train]) > 0.5).astype(int)\n",
    "y_val_pred = (model.predict([Xc_val, Xu_val]) > 0.5).astype(int)\n",
    "y_test_pred = (model.predict([Xc_test, Xu_test]) > 0.5).astype(int)\n",
    "\n",
    "# Print classification reports for all sets\n",
    "print(\"Train Set Classification Report:\\n\", classification_report(y_train, y_train_pred,digits=4))\n",
    "print(\"Validation Set Classification Report:\\n\", classification_report(y_val, y_val_pred,digits=4))\n",
    "print(\"Test Set Classification Report:\\n\", classification_report(y_test, y_test_pred,digits=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-21T05:56:47.472643Z",
     "iopub.status.busy": "2025-03-21T05:56:47.472223Z",
     "iopub.status.idle": "2025-03-21T05:56:58.141098Z",
     "shell.execute_reply": "2025-03-21T05:56:58.140233Z",
     "shell.execute_reply.started": "2025-03-21T05:56:47.472610Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_18\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_18\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_36            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ input_layer_37            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_61 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">98,432</span> │ input_layer_36[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_63 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">98,432</span> │ input_layer_37[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_62 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dense_61[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_64 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dense_63[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ concatenate_18            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_62[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ dense_64[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_65 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ concatenate_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_66 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ dense_65[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_36            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ input_layer_37            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_61 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m98,432\u001b[0m │ input_layer_36[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_63 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m98,432\u001b[0m │ input_layer_37[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_62 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │          \u001b[38;5;34m8,256\u001b[0m │ dense_61[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_64 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │          \u001b[38;5;34m8,256\u001b[0m │ dense_63[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ concatenate_18            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ dense_62[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ dense_64[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_65 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │          \u001b[38;5;34m8,256\u001b[0m │ concatenate_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_66 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m65\u001b[0m │ dense_65[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">221,697</span> (866.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m221,697\u001b[0m (866.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">221,697</span> (866.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m221,697\u001b[0m (866.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5966 - loss: 0.6881\n",
      "Epoch 1: val_accuracy improved from -inf to 0.55833, saving model to /kaggle/working/wav2vec2_base_fcn_model.weights.h5\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 61ms/step - accuracy: 0.5964 - loss: 0.6881 - val_accuracy: 0.5583 - val_loss: 0.6609\n",
      "Epoch 2/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5938 - loss: 0.6271\n",
      "Epoch 2: val_accuracy improved from 0.55833 to 0.58333, saving model to /kaggle/working/wav2vec2_base_fcn_model.weights.h5\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6788 - loss: 0.6117 - val_accuracy: 0.5833 - val_loss: 0.6826\n",
      "Epoch 3/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5938 - loss: 0.6526\n",
      "Epoch 3: val_accuracy improved from 0.58333 to 0.59167, saving model to /kaggle/working/wav2vec2_base_fcn_model.weights.h5\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6540 - loss: 0.6211 - val_accuracy: 0.5917 - val_loss: 0.6923\n",
      "Epoch 4/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7812 - loss: 0.5119\n",
      "Epoch 4: val_accuracy did not improve from 0.59167\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6991 - loss: 0.5820 - val_accuracy: 0.5750 - val_loss: 0.6803\n",
      "Epoch 5/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6875 - loss: 0.5893\n",
      "Epoch 5: val_accuracy improved from 0.59167 to 0.64167, saving model to /kaggle/working/wav2vec2_base_fcn_model.weights.h5\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6987 - loss: 0.5843 - val_accuracy: 0.6417 - val_loss: 0.6581\n",
      "Epoch 6/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6250 - loss: 0.6065\n",
      "Epoch 6: val_accuracy did not improve from 0.64167\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6969 - loss: 0.5770 - val_accuracy: 0.6250 - val_loss: 0.7575\n",
      "Epoch 7/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8125 - loss: 0.3507\n",
      "Epoch 7: val_accuracy did not improve from 0.64167\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7184 - loss: 0.5553 - val_accuracy: 0.6417 - val_loss: 0.7401\n",
      "Epoch 8/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6250 - loss: 0.6620\n",
      "Epoch 8: val_accuracy did not improve from 0.64167\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7237 - loss: 0.5312 - val_accuracy: 0.6417 - val_loss: 0.6800\n",
      "Epoch 9/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7812 - loss: 0.3773\n",
      "Epoch 9: val_accuracy improved from 0.64167 to 0.66667, saving model to /kaggle/working/wav2vec2_base_fcn_model.weights.h5\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7516 - loss: 0.4857 - val_accuracy: 0.6667 - val_loss: 0.6691\n",
      "Epoch 10/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7812 - loss: 0.5136\n",
      "Epoch 10: val_accuracy did not improve from 0.66667\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7458 - loss: 0.5078 - val_accuracy: 0.6333 - val_loss: 0.6539\n",
      "Epoch 11/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6562 - loss: 0.5629\n",
      "Epoch 11: val_accuracy did not improve from 0.66667\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7569 - loss: 0.4862 - val_accuracy: 0.6333 - val_loss: 0.6775\n",
      "Epoch 12/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7812 - loss: 0.4368\n",
      "Epoch 12: val_accuracy did not improve from 0.66667\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7317 - loss: 0.5206 - val_accuracy: 0.6667 - val_loss: 0.6628\n",
      "Epoch 13/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8125 - loss: 0.4136\n",
      "Epoch 13: val_accuracy did not improve from 0.66667\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7814 - loss: 0.4516 - val_accuracy: 0.6333 - val_loss: 0.8260\n",
      "Epoch 14/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6875 - loss: 0.6080\n",
      "Epoch 14: val_accuracy did not improve from 0.66667\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7920 - loss: 0.4530 - val_accuracy: 0.6583 - val_loss: 0.7376\n",
      "Epoch 15/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8750 - loss: 0.3402\n",
      "Epoch 15: val_accuracy did not improve from 0.66667\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8033 - loss: 0.4467 - val_accuracy: 0.6167 - val_loss: 0.6675\n",
      "Epoch 16/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9688 - loss: 0.2917\n",
      "Epoch 16: val_accuracy did not improve from 0.66667\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8291 - loss: 0.4012 - val_accuracy: 0.6500 - val_loss: 0.6917\n",
      "Epoch 17/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7188 - loss: 0.5226\n",
      "Epoch 17: val_accuracy did not improve from 0.66667\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8191 - loss: 0.3966 - val_accuracy: 0.6167 - val_loss: 0.7899\n",
      "Epoch 18/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7500 - loss: 0.4987\n",
      "Epoch 18: val_accuracy did not improve from 0.66667\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8151 - loss: 0.3846 - val_accuracy: 0.6583 - val_loss: 0.7566\n",
      "Epoch 19/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8750 - loss: 0.3373\n",
      "Epoch 19: val_accuracy did not improve from 0.66667\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7895 - loss: 0.4410 - val_accuracy: 0.6083 - val_loss: 0.7321\n",
      "Epoch 20/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9062 - loss: 0.2859\n",
      "Epoch 20: val_accuracy did not improve from 0.66667\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8300 - loss: 0.3823 - val_accuracy: 0.6667 - val_loss: 0.7787\n",
      "Epoch 21/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7812 - loss: 0.3571\n",
      "Epoch 21: val_accuracy did not improve from 0.66667\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8357 - loss: 0.3495 - val_accuracy: 0.6417 - val_loss: 0.7484\n",
      "Epoch 22/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7188 - loss: 0.4462\n",
      "Epoch 22: val_accuracy did not improve from 0.66667\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8361 - loss: 0.3486 - val_accuracy: 0.6333 - val_loss: 0.8753\n",
      "Epoch 23/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8438 - loss: 0.3751\n",
      "Epoch 23: val_accuracy did not improve from 0.66667\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8487 - loss: 0.3253 - val_accuracy: 0.6250 - val_loss: 0.8382\n",
      "Epoch 24/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9375 - loss: 0.2428\n",
      "Epoch 24: val_accuracy did not improve from 0.66667\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8885 - loss: 0.2830 - val_accuracy: 0.6500 - val_loss: 0.8473\n",
      "Epoch 25/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8750 - loss: 0.2865\n",
      "Epoch 25: val_accuracy did not improve from 0.66667\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8917 - loss: 0.2745 - val_accuracy: 0.6417 - val_loss: 0.8386\n",
      "Epoch 26/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9375 - loss: 0.2337\n",
      "Epoch 26: val_accuracy did not improve from 0.66667\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8417 - loss: 0.3497 - val_accuracy: 0.6167 - val_loss: 0.9174\n",
      "Epoch 27/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8750 - loss: 0.2982\n",
      "Epoch 27: val_accuracy did not improve from 0.66667\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8946 - loss: 0.2801 - val_accuracy: 0.6417 - val_loss: 0.8682\n",
      "Epoch 28/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9062 - loss: 0.1990\n",
      "Epoch 28: val_accuracy did not improve from 0.66667\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8859 - loss: 0.2627 - val_accuracy: 0.6417 - val_loss: 0.8694\n",
      "Epoch 29/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8125 - loss: 0.3136\n",
      "Epoch 29: val_accuracy did not improve from 0.66667\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9086 - loss: 0.2327 - val_accuracy: 0.5917 - val_loss: 0.8504\n",
      "Epoch 30/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9375 - loss: 0.1922\n",
      "Epoch 30: val_accuracy did not improve from 0.66667\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9155 - loss: 0.2184 - val_accuracy: 0.6500 - val_loss: 0.8899\n",
      "Epoch 31/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9062 - loss: 0.2253\n",
      "Epoch 31: val_accuracy did not improve from 0.66667\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9278 - loss: 0.2094 - val_accuracy: 0.6083 - val_loss: 1.1035\n",
      "Epoch 32/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8125 - loss: 0.3804\n",
      "Epoch 32: val_accuracy did not improve from 0.66667\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8840 - loss: 0.2674 - val_accuracy: 0.6417 - val_loss: 1.0010\n",
      "Epoch 33/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0917\n",
      "Epoch 33: val_accuracy did not improve from 0.66667\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9343 - loss: 0.2095 - val_accuracy: 0.6500 - val_loss: 1.0240\n",
      "Epoch 34/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9688 - loss: 0.1537\n",
      "Epoch 34: val_accuracy did not improve from 0.66667\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9466 - loss: 0.1657 - val_accuracy: 0.6250 - val_loss: 1.1022\n",
      "Epoch 35/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0818\n",
      "Epoch 35: val_accuracy did not improve from 0.66667\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9539 - loss: 0.1570 - val_accuracy: 0.6250 - val_loss: 1.1038\n",
      "Epoch 36/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9375 - loss: 0.1266\n",
      "Epoch 36: val_accuracy did not improve from 0.66667\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9463 - loss: 0.1600 - val_accuracy: 0.6250 - val_loss: 1.0818\n",
      "Epoch 37/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9062 - loss: 0.1705\n",
      "Epoch 37: val_accuracy did not improve from 0.66667\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9341 - loss: 0.1745 - val_accuracy: 0.5833 - val_loss: 0.9962\n",
      "Epoch 38/50\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9676 - loss: 0.1282 \n",
      "Epoch 38: val_accuracy improved from 0.66667 to 0.67500, saving model to /kaggle/working/wav2vec2_base_fcn_model.weights.h5\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9676 - loss: 0.1282 - val_accuracy: 0.6750 - val_loss: 1.0812\n",
      "Epoch 39/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9375 - loss: 0.1548\n",
      "Epoch 39: val_accuracy did not improve from 0.67500\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9798 - loss: 0.1028 - val_accuracy: 0.6250 - val_loss: 1.0238\n",
      "Epoch 40/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0713\n",
      "Epoch 40: val_accuracy did not improve from 0.67500\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9627 - loss: 0.1276 - val_accuracy: 0.6417 - val_loss: 1.0104\n",
      "Epoch 41/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9688 - loss: 0.1394\n",
      "Epoch 41: val_accuracy did not improve from 0.67500\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9692 - loss: 0.1260 - val_accuracy: 0.6500 - val_loss: 1.1460\n",
      "Epoch 42/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.0647\n",
      "Epoch 42: val_accuracy did not improve from 0.67500\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9725 - loss: 0.0952 - val_accuracy: 0.6000 - val_loss: 1.1416\n",
      "Epoch 43/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9688 - loss: 0.1133\n",
      "Epoch 43: val_accuracy did not improve from 0.67500\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9797 - loss: 0.0973 - val_accuracy: 0.6167 - val_loss: 1.1749\n",
      "Epoch 44/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0595\n",
      "Epoch 44: val_accuracy did not improve from 0.67500\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9790 - loss: 0.0872 - val_accuracy: 0.6000 - val_loss: 1.2125\n",
      "Epoch 45/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0514\n",
      "Epoch 45: val_accuracy did not improve from 0.67500\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9943 - loss: 0.0705 - val_accuracy: 0.6667 - val_loss: 1.1735\n",
      "Epoch 46/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0517\n",
      "Epoch 46: val_accuracy did not improve from 0.67500\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9881 - loss: 0.0636 - val_accuracy: 0.6500 - val_loss: 1.1241\n",
      "Epoch 47/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0544\n",
      "Epoch 47: val_accuracy did not improve from 0.67500\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9970 - loss: 0.0472 - val_accuracy: 0.6417 - val_loss: 1.2450\n",
      "Epoch 48/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0198\n",
      "Epoch 48: val_accuracy did not improve from 0.67500\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9959 - loss: 0.0567 - val_accuracy: 0.6500 - val_loss: 1.3602\n",
      "Epoch 49/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9375 - loss: 0.1158\n",
      "Epoch 49: val_accuracy did not improve from 0.67500\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9843 - loss: 0.0570 - val_accuracy: 0.6583 - val_loss: 1.1841\n",
      "Epoch 50/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0266\n",
      "Epoch 50: val_accuracy did not improve from 0.67500\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9967 - loss: 0.0369 - val_accuracy: 0.6250 - val_loss: 1.2760\n",
      "Loaded Best Model Weights.\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "Train Set Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9563    0.9905    0.9731       420\n",
      "         1.0     0.9901    0.9549    0.9722       421\n",
      "\n",
      "    accuracy                         0.9727       841\n",
      "   macro avg     0.9732    0.9727    0.9726       841\n",
      "weighted avg     0.9733    0.9727    0.9726       841\n",
      "\n",
      "Validation Set Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6567    0.7333    0.6929        60\n",
      "         1.0     0.6981    0.6167    0.6549        60\n",
      "\n",
      "    accuracy                         0.6750       120\n",
      "   macro avg     0.6774    0.6750    0.6739       120\n",
      "weighted avg     0.6774    0.6750    0.6739       120\n",
      "\n",
      "Test Set Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6810    0.6529    0.6667       121\n",
      "         1.0     0.6640    0.6917    0.6776       120\n",
      "\n",
      "    accuracy                         0.6722       241\n",
      "   macro avg     0.6725    0.6723    0.6721       241\n",
      "weighted avg     0.6726    0.6722    0.6721       241\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "FCN MODEL\n",
    "\"\"\"\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Load the final dataset\n",
    "df = pd.read_csv(\"/kaggle/input/btp-audioembeddings/audio_features_Wav2Vec2_base.csv\")\n",
    "\n",
    "# Extract labels\n",
    "y = df[\"Sarcasm\"].values  # Labels (0: No sarcasm, 1: Sarcasm)\n",
    "\n",
    "# Extract context and utterance features\n",
    "X_context = df[[col for col in df.columns if col.startswith(\"audio_c_feature_\")]].values\n",
    "X_utterance = df[[col for col in df.columns if col.startswith(\"audio_u_feature_\")]].values\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "X_context = np.array(X_context, dtype=np.float32)\n",
    "X_utterance = np.array(X_utterance, dtype=np.float32)\n",
    "y = np.array(y, dtype=np.float32)\n",
    "\n",
    "# First, split into train (70%) and temp (30%) \n",
    "Xc_train, Xc_temp, Xu_train, Xu_temp, y_train, y_temp = train_test_split(\n",
    "    X_context, X_utterance, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Split temp (30%) into validation (10%) and test (20%)\n",
    "Xc_val, Xc_test, Xu_val, Xu_test, y_val, y_test = train_test_split(\n",
    "    Xc_temp, Xu_temp, y_temp, test_size=2/3, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "# FCN Model for Sarcasm Detection\n",
    "input_dim = 768  # Number of features per input\n",
    "\n",
    "# Context Branch (Fully Connected Layers)\n",
    "input_context = keras.Input(shape=(input_dim,))\n",
    "context_branch = layers.Dense(128, activation=\"tanh\")(input_context)\n",
    "context_branch = layers.Dense(64, activation=\"tanh\")(context_branch)\n",
    "\n",
    "# Utterance Branch (Fully Connected Layers)\n",
    "input_utterance = keras.Input(shape=(input_dim,))\n",
    "utterance_branch = layers.Dense(128, activation=\"tanh\")(input_utterance)\n",
    "utterance_branch = layers.Dense(64, activation=\"tanh\")(utterance_branch)\n",
    "\n",
    "# Concatenation\n",
    "merged = layers.Concatenate()([context_branch, utterance_branch])\n",
    "merged = layers.Dense(64, activation=\"tanh\")(merged)\n",
    "output = layers.Dense(1, activation=\"sigmoid\")(merged)  # Sigmoid for binary classification\n",
    "\n",
    "# Define Model\n",
    "model = keras.Model(inputs=[input_context, input_utterance], outputs=output)\n",
    "model.summary()\n",
    "\n",
    "# Compile Model\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Checkpoint to save the best model based on validation accuracy\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    \"/kaggle/working/wav2vec2_base_fcn_model.weights.h5\",\n",
    "    monitor=\"val_accuracy\",\n",
    "    mode=\"max\",\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train Model\n",
    "model.fit(\n",
    "    [Xc_train, Xu_train], y_train,\n",
    "    epochs=50, batch_size=32,\n",
    "    validation_data=([Xc_val, Xu_val], y_val),\n",
    "    callbacks=[checkpoint_callback]\n",
    ")\n",
    "\n",
    "# Load best model weights\n",
    "model.load_weights(\"/kaggle/working/wav2vec2_base_fcn_model.weights.h5\")\n",
    "print(\"Loaded Best Model Weights.\")\n",
    "\n",
    "# Generate predictions using the best model\n",
    "y_train_pred = (model.predict([Xc_train, Xu_train]) > 0.5).astype(int)\n",
    "y_val_pred = (model.predict([Xc_val, Xu_val]) > 0.5).astype(int)\n",
    "y_test_pred = (model.predict([Xc_test, Xu_test]) > 0.5).astype(int)\n",
    "\n",
    "# Print classification reports\n",
    "print(\"Train Set Classification Report:\\n\", classification_report(y_train, y_train_pred, digits=4))\n",
    "print(\"Validation Set Classification Report:\\n\", classification_report(y_val, y_val_pred, digits=4))\n",
    "print(\"Test Set Classification Report:\\n\", classification_report(y_test, y_test_pred, digits=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Trained on HUBERT Embeddings\n",
    "\n",
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-21T19:15:51.976611Z",
     "iopub.status.busy": "2025-03-21T19:15:51.976275Z",
     "iopub.status.idle": "2025-03-21T19:16:04.483894Z",
     "shell.execute_reply": "2025-03-21T19:16:04.483158Z",
     "shell.execute_reply.started": "2025-03-21T19:15:51.976581Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_6\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_6\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_12            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ input_layer_13            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ reshape_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ reshape_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv1d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">766</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ reshape_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv1d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">766</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ reshape_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ max_pooling1d_12          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">383</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)            │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ max_pooling1d_13          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">383</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)            │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ flatten_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">49024</span>)          │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ flatten_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">49024</span>)          │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ concatenate_6             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">98048</span>)          │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ flatten_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">98,049</span> │ concatenate_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_12            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ input_layer_13            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ reshape_12 (\u001b[38;5;33mReshape\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ input_layer_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ reshape_13 (\u001b[38;5;33mReshape\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ input_layer_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv1d_12 (\u001b[38;5;33mConv1D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m766\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │            \u001b[38;5;34m512\u001b[0m │ reshape_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv1d_13 (\u001b[38;5;33mConv1D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m766\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │            \u001b[38;5;34m512\u001b[0m │ reshape_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ max_pooling1d_12          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m383\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ conv1d_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)            │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ max_pooling1d_13          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m383\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ conv1d_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)            │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ flatten_12 (\u001b[38;5;33mFlatten\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m49024\u001b[0m)          │              \u001b[38;5;34m0\u001b[0m │ max_pooling1d_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ flatten_13 (\u001b[38;5;33mFlatten\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m49024\u001b[0m)          │              \u001b[38;5;34m0\u001b[0m │ max_pooling1d_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ concatenate_6             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m98048\u001b[0m)          │              \u001b[38;5;34m0\u001b[0m │ flatten_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ flatten_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │         \u001b[38;5;34m98,049\u001b[0m │ concatenate_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">99,073</span> (387.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m99,073\u001b[0m (387.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">99,073</span> (387.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m99,073\u001b[0m (387.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5631 - loss: 0.6716\n",
      "Epoch 1: val_accuracy improved from -inf to 0.60833, saving model to /kaggle/working/hubert_cnn_model.weights.h5\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 107ms/step - accuracy: 0.5643 - loss: 0.6711 - val_accuracy: 0.6083 - val_loss: 0.6563\n",
      "Epoch 2/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6580 - loss: 0.6109 \n",
      "Epoch 2: val_accuracy improved from 0.60833 to 0.61667, saving model to /kaggle/working/hubert_cnn_model.weights.h5\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6609 - loss: 0.6086 - val_accuracy: 0.6167 - val_loss: 0.6386\n",
      "Epoch 3/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6565 - loss: 0.6061 \n",
      "Epoch 3: val_accuracy improved from 0.61667 to 0.64167, saving model to /kaggle/working/hubert_cnn_model.weights.h5\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6612 - loss: 0.6024 - val_accuracy: 0.6417 - val_loss: 0.6299\n",
      "Epoch 4/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7112 - loss: 0.5660 \n",
      "Epoch 4: val_accuracy did not improve from 0.64167\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7088 - loss: 0.5661 - val_accuracy: 0.6250 - val_loss: 0.6172\n",
      "Epoch 5/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6801 - loss: 0.5815 \n",
      "Epoch 5: val_accuracy improved from 0.64167 to 0.65000, saving model to /kaggle/working/hubert_cnn_model.weights.h5\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6877 - loss: 0.5766 - val_accuracy: 0.6500 - val_loss: 0.6164\n",
      "Epoch 6/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7444 - loss: 0.5335 \n",
      "Epoch 6: val_accuracy did not improve from 0.65000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7440 - loss: 0.5340 - val_accuracy: 0.6417 - val_loss: 0.6342\n",
      "Epoch 7/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7396 - loss: 0.5316 \n",
      "Epoch 7: val_accuracy improved from 0.65000 to 0.66667, saving model to /kaggle/working/hubert_cnn_model.weights.h5\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7429 - loss: 0.5283 - val_accuracy: 0.6667 - val_loss: 0.6080\n",
      "Epoch 8/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7671 - loss: 0.5057 \n",
      "Epoch 8: val_accuracy improved from 0.66667 to 0.67500, saving model to /kaggle/working/hubert_cnn_model.weights.h5\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7666 - loss: 0.5048 - val_accuracy: 0.6750 - val_loss: 0.6252\n",
      "Epoch 9/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7823 - loss: 0.4764 \n",
      "Epoch 9: val_accuracy did not improve from 0.67500\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7805 - loss: 0.4773 - val_accuracy: 0.6667 - val_loss: 0.6063\n",
      "Epoch 10/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7432 - loss: 0.5248 \n",
      "Epoch 10: val_accuracy did not improve from 0.67500\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7468 - loss: 0.5188 - val_accuracy: 0.6500 - val_loss: 0.6324\n",
      "Epoch 11/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7885 - loss: 0.4717 \n",
      "Epoch 11: val_accuracy did not improve from 0.67500\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7886 - loss: 0.4708 - val_accuracy: 0.6417 - val_loss: 0.6415\n",
      "Epoch 12/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8446 - loss: 0.4102 \n",
      "Epoch 12: val_accuracy did not improve from 0.67500\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8368 - loss: 0.4160 - val_accuracy: 0.6583 - val_loss: 0.6356\n",
      "Epoch 13/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7900 - loss: 0.4444 \n",
      "Epoch 13: val_accuracy did not improve from 0.67500\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7925 - loss: 0.4423 - val_accuracy: 0.6583 - val_loss: 0.6483\n",
      "Epoch 14/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8138 - loss: 0.4188 \n",
      "Epoch 14: val_accuracy did not improve from 0.67500\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8139 - loss: 0.4188 - val_accuracy: 0.6167 - val_loss: 0.6986\n",
      "Epoch 15/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8141 - loss: 0.4058 \n",
      "Epoch 15: val_accuracy did not improve from 0.67500\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8122 - loss: 0.4080 - val_accuracy: 0.6500 - val_loss: 0.6413\n",
      "Epoch 16/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8292 - loss: 0.4013 \n",
      "Epoch 16: val_accuracy did not improve from 0.67500\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8317 - loss: 0.3964 - val_accuracy: 0.6417 - val_loss: 0.6813\n",
      "Epoch 17/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8348 - loss: 0.3909 \n",
      "Epoch 17: val_accuracy did not improve from 0.67500\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8365 - loss: 0.3891 - val_accuracy: 0.6167 - val_loss: 0.6647\n",
      "Epoch 18/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8691 - loss: 0.3347 \n",
      "Epoch 18: val_accuracy did not improve from 0.67500\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8668 - loss: 0.3376 - val_accuracy: 0.6417 - val_loss: 0.6786\n",
      "Epoch 19/50\n",
      "\u001b[1m21/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8908 - loss: 0.3367 \n",
      "Epoch 19: val_accuracy did not improve from 0.67500\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8859 - loss: 0.3388 - val_accuracy: 0.6417 - val_loss: 0.7577\n",
      "Epoch 20/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8485 - loss: 0.3505 \n",
      "Epoch 20: val_accuracy did not improve from 0.67500\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8515 - loss: 0.3497 - val_accuracy: 0.6583 - val_loss: 0.7319\n",
      "Epoch 21/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8727 - loss: 0.3350 \n",
      "Epoch 21: val_accuracy did not improve from 0.67500\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8717 - loss: 0.3347 - val_accuracy: 0.6083 - val_loss: 0.7230\n",
      "Epoch 22/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8958 - loss: 0.2763 \n",
      "Epoch 22: val_accuracy did not improve from 0.67500\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8942 - loss: 0.2805 - val_accuracy: 0.6250 - val_loss: 0.7110\n",
      "Epoch 23/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9000 - loss: 0.2738 \n",
      "Epoch 23: val_accuracy did not improve from 0.67500\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8989 - loss: 0.2761 - val_accuracy: 0.6667 - val_loss: 0.7178\n",
      "Epoch 24/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9065 - loss: 0.2624 \n",
      "Epoch 24: val_accuracy did not improve from 0.67500\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9047 - loss: 0.2640 - val_accuracy: 0.6167 - val_loss: 0.6991\n",
      "Epoch 25/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9385 - loss: 0.2466 \n",
      "Epoch 25: val_accuracy did not improve from 0.67500\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9336 - loss: 0.2508 - val_accuracy: 0.6083 - val_loss: 0.7387\n",
      "Epoch 26/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9098 - loss: 0.2493 \n",
      "Epoch 26: val_accuracy did not improve from 0.67500\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9083 - loss: 0.2508 - val_accuracy: 0.6000 - val_loss: 0.7308\n",
      "Epoch 27/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9387 - loss: 0.2277 \n",
      "Epoch 27: val_accuracy did not improve from 0.67500\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9343 - loss: 0.2308 - val_accuracy: 0.6750 - val_loss: 0.8546\n",
      "Epoch 28/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8743 - loss: 0.2834 \n",
      "Epoch 28: val_accuracy did not improve from 0.67500\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8760 - loss: 0.2827 - val_accuracy: 0.6333 - val_loss: 0.8477\n",
      "Epoch 29/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9201 - loss: 0.2226 \n",
      "Epoch 29: val_accuracy did not improve from 0.67500\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9201 - loss: 0.2227 - val_accuracy: 0.6333 - val_loss: 0.7615\n",
      "Epoch 30/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9266 - loss: 0.2191 \n",
      "Epoch 30: val_accuracy did not improve from 0.67500\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9268 - loss: 0.2188 - val_accuracy: 0.6333 - val_loss: 0.8028\n",
      "Epoch 31/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9477 - loss: 0.2005 \n",
      "Epoch 31: val_accuracy did not improve from 0.67500\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9452 - loss: 0.2017 - val_accuracy: 0.6500 - val_loss: 0.8243\n",
      "Epoch 32/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9278 - loss: 0.2190 \n",
      "Epoch 32: val_accuracy did not improve from 0.67500\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9287 - loss: 0.2189 - val_accuracy: 0.5917 - val_loss: 0.8420\n",
      "Epoch 33/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9444 - loss: 0.1760 \n",
      "Epoch 33: val_accuracy did not improve from 0.67500\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9452 - loss: 0.1771 - val_accuracy: 0.6417 - val_loss: 0.8109\n",
      "Epoch 34/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9681 - loss: 0.1724 \n",
      "Epoch 34: val_accuracy did not improve from 0.67500\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9653 - loss: 0.1741 - val_accuracy: 0.5917 - val_loss: 0.8539\n",
      "Epoch 35/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9470 - loss: 0.1823 \n",
      "Epoch 35: val_accuracy did not improve from 0.67500\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9469 - loss: 0.1809 - val_accuracy: 0.6083 - val_loss: 0.8570\n",
      "Epoch 36/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9608 - loss: 0.1493 \n",
      "Epoch 36: val_accuracy did not improve from 0.67500\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9596 - loss: 0.1524 - val_accuracy: 0.6167 - val_loss: 0.8815\n",
      "Epoch 37/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9707 - loss: 0.1482 \n",
      "Epoch 37: val_accuracy did not improve from 0.67500\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9704 - loss: 0.1492 - val_accuracy: 0.6083 - val_loss: 0.8806\n",
      "Epoch 38/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9444 - loss: 0.1669 \n",
      "Epoch 38: val_accuracy did not improve from 0.67500\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9441 - loss: 0.1677 - val_accuracy: 0.6333 - val_loss: 0.8738\n",
      "Epoch 39/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9648 - loss: 0.1469 \n",
      "Epoch 39: val_accuracy did not improve from 0.67500\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9661 - loss: 0.1456 - val_accuracy: 0.6333 - val_loss: 0.9154\n",
      "Epoch 40/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9835 - loss: 0.1302 \n",
      "Epoch 40: val_accuracy did not improve from 0.67500\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9822 - loss: 0.1310 - val_accuracy: 0.6333 - val_loss: 0.9687\n",
      "Epoch 41/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9605 - loss: 0.1477 \n",
      "Epoch 41: val_accuracy did not improve from 0.67500\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9621 - loss: 0.1462 - val_accuracy: 0.6167 - val_loss: 0.9107\n",
      "Epoch 42/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9874 - loss: 0.1185 \n",
      "Epoch 42: val_accuracy did not improve from 0.67500\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9854 - loss: 0.1200 - val_accuracy: 0.6417 - val_loss: 0.9183\n",
      "Epoch 43/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9866 - loss: 0.1108 \n",
      "Epoch 43: val_accuracy did not improve from 0.67500\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9861 - loss: 0.1111 - val_accuracy: 0.6417 - val_loss: 0.9360\n",
      "Epoch 44/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9920 - loss: 0.1076 \n",
      "Epoch 44: val_accuracy did not improve from 0.67500\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9900 - loss: 0.1084 - val_accuracy: 0.6083 - val_loss: 0.9317\n",
      "Epoch 45/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9814 - loss: 0.1125 \n",
      "Epoch 45: val_accuracy did not improve from 0.67500\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9820 - loss: 0.1114 - val_accuracy: 0.6333 - val_loss: 0.9711\n",
      "Epoch 46/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9940 - loss: 0.0886 \n",
      "Epoch 46: val_accuracy did not improve from 0.67500\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9935 - loss: 0.0905 - val_accuracy: 0.6500 - val_loss: 0.9793\n",
      "Epoch 47/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9952 - loss: 0.0909 \n",
      "Epoch 47: val_accuracy did not improve from 0.67500\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9950 - loss: 0.0905 - val_accuracy: 0.6250 - val_loss: 1.0062\n",
      "Epoch 48/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9931 - loss: 0.0878 \n",
      "Epoch 48: val_accuracy did not improve from 0.67500\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9930 - loss: 0.0885 - val_accuracy: 0.6167 - val_loss: 1.0053\n",
      "Epoch 49/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9968 - loss: 0.0849 \n",
      "Epoch 49: val_accuracy did not improve from 0.67500\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9967 - loss: 0.0843 - val_accuracy: 0.6333 - val_loss: 1.0358\n",
      "Epoch 50/50\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9971 - loss: 0.0873 \n",
      "Epoch 50: val_accuracy did not improve from 0.67500\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9969 - loss: 0.0859 - val_accuracy: 0.6417 - val_loss: 1.0678\n",
      "Loaded Best Model Weights.\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "Train Set Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8623    0.6262    0.7255       420\n",
      "         1.0     0.7071    0.9002    0.7921       421\n",
      "\n",
      "    accuracy                         0.7634       841\n",
      "   macro avg     0.7847    0.7632    0.7588       841\n",
      "weighted avg     0.7846    0.7634    0.7588       841\n",
      "\n",
      "Validation Set Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7234    0.5667    0.6355        60\n",
      "         1.0     0.6438    0.7833    0.7068        60\n",
      "\n",
      "    accuracy                         0.6750       120\n",
      "   macro avg     0.6836    0.6750    0.6711       120\n",
      "weighted avg     0.6836    0.6750    0.6711       120\n",
      "\n",
      "Test Set Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8358    0.4628    0.5957       121\n",
      "         1.0     0.6264    0.9083    0.7415       120\n",
      "\n",
      "    accuracy                         0.6846       241\n",
      "   macro avg     0.7311    0.6856    0.6686       241\n",
      "weighted avg     0.7316    0.6846    0.6683       241\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "CNN MODEL\n",
    "\"\"\"\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Load the final dataset\n",
    "df = pd.read_csv(\"/kaggle/input/btp-audioembeddings/audio_features_hubert.csv\")\n",
    "\n",
    "# Extract labels\n",
    "y = df[\"Sarcasm\"].values  # Labels (0: No sarcasm, 1: Sarcasm)\n",
    "\n",
    "# Extract context features (from csv1_)\n",
    "X_context = df[[col for col in df.columns if col.startswith(\"audio_c_feature_\")]].values\n",
    "\n",
    "# Extract utterance features (from csv2_)\n",
    "X_utterance = df[[col for col in df.columns if col.startswith(\"audio_u_feature_\")]].values\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "X_context = np.array(X_context, dtype=np.float32)\n",
    "X_utterance = np.array(X_utterance, dtype=np.float32)\n",
    "y = np.array(y, dtype=np.float32)\n",
    "\n",
    "# First, split into train (70%) and temp (30%) \n",
    "Xc_train, Xc_temp, Xu_train, Xu_temp, y_train, y_temp = train_test_split(\n",
    "    X_context, X_utterance, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Split temp (30%) into validation (10%) and test (20%)\n",
    "Xc_val, Xc_test, Xu_val, Xu_test, y_val, y_test = train_test_split(\n",
    "    Xc_temp, Xu_temp, y_temp, test_size=2/3, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "# CNN Model for Sarcasm Detection\n",
    "input_dim = 768  # Number of features per input\n",
    "\n",
    "# Context Branch\n",
    "input_context = keras.Input(shape=(input_dim,))\n",
    "context_branch = layers.Reshape((input_dim, 1))(input_context)\n",
    "context_branch = layers.Conv1D(filters=128, kernel_size=3, activation=\"swish\")(context_branch)\n",
    "context_branch = layers.MaxPooling1D(pool_size=2)(context_branch)\n",
    "context_branch = layers.Flatten()(context_branch)\n",
    "\n",
    "# Utterance Branch\n",
    "input_utterance = keras.Input(shape=(input_dim,))\n",
    "utterance_branch = layers.Reshape((input_dim, 1))(input_utterance)\n",
    "utterance_branch = layers.Conv1D(filters=128, kernel_size=3, activation=\"swish\")(utterance_branch)\n",
    "utterance_branch = layers.MaxPooling1D(pool_size=2)(utterance_branch)\n",
    "utterance_branch = layers.Flatten()(utterance_branch)\n",
    "\n",
    "# Concatenation\n",
    "merged = layers.Concatenate()([context_branch, utterance_branch])\n",
    "#merged = layers.Dense(768, activation=\"swish\")(merged)\n",
    "#merged = layers.Dense(32, activation=\"swish\")(merged)\n",
    "output = layers.Dense(1, activation=\"sigmoid\")(merged)  # Sigmoid for binary classification\n",
    "\n",
    "# Define Model\n",
    "model = keras.Model(inputs=[input_context, input_utterance], outputs=output)\n",
    "model.summary()\n",
    "\n",
    "# Compile Model\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Checkpoint to save the best model based on validation accuracy\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    \"/kaggle/working/hubert_cnn_model.weights.h5\",\n",
    "    monitor=\"val_accuracy\",  # Monitor validation accuracy\n",
    "    mode=\"max\",  # Save when val_accuracy is maximum\n",
    "    save_best_only=True,  # Keep only the best weights\n",
    "    save_weights_only=True,  # Don't save full model\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train Model\n",
    "model.fit(\n",
    "    [Xc_train, Xu_train], y_train,\n",
    "    epochs=50, batch_size=32,\n",
    "    validation_data=([Xc_val, Xu_val], y_val),  # Use validation set\n",
    "    callbacks=[checkpoint_callback]\n",
    ")\n",
    "\n",
    "# Load best model weights\n",
    "model.load_weights(\"/kaggle/working/hubert_cnn_model.weights.h5\")\n",
    "print(\"Loaded Best Model Weights.\")\n",
    "\n",
    "# Generate predictions using the best model\n",
    "y_train_pred = (model.predict([Xc_train, Xu_train]) > 0.5).astype(int)\n",
    "y_val_pred = (model.predict([Xc_val, Xu_val]) > 0.5).astype(int)\n",
    "y_test_pred = (model.predict([Xc_test, Xu_test]) > 0.5).astype(int)\n",
    "\n",
    "# Print classification reports for all sets\n",
    "print(\"Train Set Classification Report:\\n\", classification_report(y_train, y_train_pred,digits=4))\n",
    "print(\"Validation Set Classification Report:\\n\", classification_report(y_val, y_val_pred,digits=4))\n",
    "print(\"Test Set Classification Report:\\n\", classification_report(y_test, y_test_pred,digits=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-21T19:18:18.095399Z",
     "iopub.status.busy": "2025-03-21T19:18:18.095073Z",
     "iopub.status.idle": "2025-03-21T19:18:28.786119Z",
     "shell.execute_reply": "2025-03-21T19:18:28.785198Z",
     "shell.execute_reply.started": "2025-03-21T19:18:18.095375Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_7\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_7\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_14            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ input_layer_15            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">98,432</span> │ input_layer_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">98,432</span> │ input_layer_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dense_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dense_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ concatenate_7             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ dense_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ concatenate_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ dense_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_14            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ input_layer_15            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m98,432\u001b[0m │ input_layer_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m98,432\u001b[0m │ input_layer_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │          \u001b[38;5;34m8,256\u001b[0m │ dense_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_18 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │          \u001b[38;5;34m8,256\u001b[0m │ dense_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ concatenate_7             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ dense_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ dense_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_19 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │          \u001b[38;5;34m8,256\u001b[0m │ concatenate_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_20 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m65\u001b[0m │ dense_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">221,697</span> (866.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m221,697\u001b[0m (866.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">221,697</span> (866.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m221,697\u001b[0m (866.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6349 - loss: 0.6403\n",
      "Epoch 1: val_accuracy improved from -inf to 0.65833, saving model to /kaggle/working/hubert_fcn_model.weights.h5\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 61ms/step - accuracy: 0.6351 - loss: 0.6402 - val_accuracy: 0.6583 - val_loss: 0.6296\n",
      "Epoch 2/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8125 - loss: 0.5503\n",
      "Epoch 2: val_accuracy did not improve from 0.65833\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6878 - loss: 0.5940 - val_accuracy: 0.6333 - val_loss: 0.6912\n",
      "Epoch 3/50\n",
      "\u001b[1m23/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6839 - loss: 0.5978 \n",
      "Epoch 3: val_accuracy did not improve from 0.65833\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6891 - loss: 0.5933 - val_accuracy: 0.6417 - val_loss: 0.6284\n",
      "Epoch 4/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8438 - loss: 0.4853\n",
      "Epoch 4: val_accuracy did not improve from 0.65833\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7476 - loss: 0.5038 - val_accuracy: 0.6417 - val_loss: 0.6544\n",
      "Epoch 5/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7500 - loss: 0.5131\n",
      "Epoch 5: val_accuracy did not improve from 0.65833\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7578 - loss: 0.5050 - val_accuracy: 0.6583 - val_loss: 0.6586\n",
      "Epoch 6/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8750 - loss: 0.3798\n",
      "Epoch 6: val_accuracy improved from 0.65833 to 0.69167, saving model to /kaggle/working/hubert_fcn_model.weights.h5\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8002 - loss: 0.4425 - val_accuracy: 0.6917 - val_loss: 0.6175\n",
      "Epoch 7/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8125 - loss: 0.5118\n",
      "Epoch 7: val_accuracy did not improve from 0.69167\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7559 - loss: 0.5085 - val_accuracy: 0.6333 - val_loss: 0.6128\n",
      "Epoch 8/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.6875 - loss: 0.4986\n",
      "Epoch 8: val_accuracy did not improve from 0.69167\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7904 - loss: 0.4594 - val_accuracy: 0.6750 - val_loss: 0.6204\n",
      "Epoch 9/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9375 - loss: 0.3165\n",
      "Epoch 9: val_accuracy did not improve from 0.69167\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8266 - loss: 0.3912 - val_accuracy: 0.6500 - val_loss: 0.6669\n",
      "Epoch 10/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8750 - loss: 0.3420\n",
      "Epoch 10: val_accuracy did not improve from 0.69167\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8222 - loss: 0.3912 - val_accuracy: 0.5917 - val_loss: 0.8561\n",
      "Epoch 11/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7812 - loss: 0.4549\n",
      "Epoch 11: val_accuracy did not improve from 0.69167\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7824 - loss: 0.4522 - val_accuracy: 0.6500 - val_loss: 0.7175\n",
      "Epoch 12/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6562 - loss: 0.5053\n",
      "Epoch 12: val_accuracy did not improve from 0.69167\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8047 - loss: 0.4007 - val_accuracy: 0.6667 - val_loss: 0.7026\n",
      "Epoch 13/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8438 - loss: 0.2915\n",
      "Epoch 13: val_accuracy did not improve from 0.69167\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8505 - loss: 0.3365 - val_accuracy: 0.6250 - val_loss: 0.7233\n",
      "Epoch 14/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8750 - loss: 0.2728\n",
      "Epoch 14: val_accuracy did not improve from 0.69167\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8855 - loss: 0.2927 - val_accuracy: 0.6000 - val_loss: 0.8286\n",
      "Epoch 15/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8438 - loss: 0.3011\n",
      "Epoch 15: val_accuracy did not improve from 0.69167\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8719 - loss: 0.3098 - val_accuracy: 0.6750 - val_loss: 0.9016\n",
      "Epoch 16/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7188 - loss: 0.4910\n",
      "Epoch 16: val_accuracy did not improve from 0.69167\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8437 - loss: 0.3118 - val_accuracy: 0.6333 - val_loss: 0.8318\n",
      "Epoch 17/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9375 - loss: 0.2637\n",
      "Epoch 17: val_accuracy did not improve from 0.69167\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9096 - loss: 0.2493 - val_accuracy: 0.6250 - val_loss: 0.8820\n",
      "Epoch 18/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9062 - loss: 0.2440\n",
      "Epoch 18: val_accuracy did not improve from 0.69167\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8840 - loss: 0.2764 - val_accuracy: 0.6583 - val_loss: 0.8266\n",
      "Epoch 19/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9375 - loss: 0.2188\n",
      "Epoch 19: val_accuracy did not improve from 0.69167\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9062 - loss: 0.2287 - val_accuracy: 0.6750 - val_loss: 1.1618\n",
      "Epoch 20/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8125 - loss: 0.3920\n",
      "Epoch 20: val_accuracy did not improve from 0.69167\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8407 - loss: 0.3377 - val_accuracy: 0.6500 - val_loss: 0.9702\n",
      "Epoch 21/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9688 - loss: 0.1066\n",
      "Epoch 21: val_accuracy did not improve from 0.69167\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9012 - loss: 0.2356 - val_accuracy: 0.6250 - val_loss: 0.9041\n",
      "Epoch 22/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9688 - loss: 0.1621\n",
      "Epoch 22: val_accuracy did not improve from 0.69167\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8784 - loss: 0.2611 - val_accuracy: 0.6583 - val_loss: 0.9690\n",
      "Epoch 23/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9062 - loss: 0.2267\n",
      "Epoch 23: val_accuracy did not improve from 0.69167\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9349 - loss: 0.1792 - val_accuracy: 0.6250 - val_loss: 0.9175\n",
      "Epoch 24/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8750 - loss: 0.2254\n",
      "Epoch 24: val_accuracy did not improve from 0.69167\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9429 - loss: 0.1628 - val_accuracy: 0.6417 - val_loss: 1.0681\n",
      "Epoch 25/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.0821\n",
      "Epoch 25: val_accuracy did not improve from 0.69167\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9573 - loss: 0.1255 - val_accuracy: 0.6333 - val_loss: 1.0312\n",
      "Epoch 26/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.0870\n",
      "Epoch 26: val_accuracy did not improve from 0.69167\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9791 - loss: 0.0930 - val_accuracy: 0.6167 - val_loss: 1.2025\n",
      "Epoch 27/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0677\n",
      "Epoch 27: val_accuracy did not improve from 0.69167\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9752 - loss: 0.0996 - val_accuracy: 0.6250 - val_loss: 1.3721\n",
      "Epoch 28/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9375 - loss: 0.1275\n",
      "Epoch 28: val_accuracy did not improve from 0.69167\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9285 - loss: 0.1407 - val_accuracy: 0.6417 - val_loss: 1.2608\n",
      "Epoch 29/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9375 - loss: 0.1005\n",
      "Epoch 29: val_accuracy did not improve from 0.69167\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9741 - loss: 0.0855 - val_accuracy: 0.6167 - val_loss: 1.2558\n",
      "Epoch 30/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0610\n",
      "Epoch 30: val_accuracy did not improve from 0.69167\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9945 - loss: 0.0607 - val_accuracy: 0.5917 - val_loss: 1.3631\n",
      "Epoch 31/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.0755\n",
      "Epoch 31: val_accuracy did not improve from 0.69167\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9885 - loss: 0.0631 - val_accuracy: 0.6500 - val_loss: 1.4639\n",
      "Epoch 32/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.0301\n",
      "Epoch 32: val_accuracy did not improve from 0.69167\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9706 - loss: 0.0867 - val_accuracy: 0.6250 - val_loss: 1.4667\n",
      "Epoch 33/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.0442\n",
      "Epoch 33: val_accuracy did not improve from 0.69167\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9745 - loss: 0.0740 - val_accuracy: 0.6417 - val_loss: 1.5243\n",
      "Epoch 34/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0332\n",
      "Epoch 34: val_accuracy did not improve from 0.69167\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9950 - loss: 0.0398 - val_accuracy: 0.6167 - val_loss: 1.5595\n",
      "Epoch 35/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.0555\n",
      "Epoch 35: val_accuracy did not improve from 0.69167\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9914 - loss: 0.0457 - val_accuracy: 0.6417 - val_loss: 1.4621\n",
      "Epoch 36/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0181\n",
      "Epoch 36: val_accuracy did not improve from 0.69167\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9999 - loss: 0.0233 - val_accuracy: 0.6417 - val_loss: 1.6346\n",
      "Epoch 37/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0210\n",
      "Epoch 37: val_accuracy did not improve from 0.69167\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0172 - val_accuracy: 0.6333 - val_loss: 1.7044\n",
      "Epoch 38/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0118\n",
      "Epoch 38: val_accuracy did not improve from 0.69167\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0207 - val_accuracy: 0.6333 - val_loss: 1.7179\n",
      "Epoch 39/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0045\n",
      "Epoch 39: val_accuracy did not improve from 0.69167\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0129 - val_accuracy: 0.6333 - val_loss: 1.7893\n",
      "Epoch 40/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0097\n",
      "Epoch 40: val_accuracy did not improve from 0.69167\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0110 - val_accuracy: 0.6417 - val_loss: 1.8374\n",
      "Epoch 41/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0050\n",
      "Epoch 41: val_accuracy did not improve from 0.69167\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0079 - val_accuracy: 0.6417 - val_loss: 1.8300\n",
      "Epoch 42/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0085\n",
      "Epoch 42: val_accuracy did not improve from 0.69167\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0073 - val_accuracy: 0.6500 - val_loss: 1.9058\n",
      "Epoch 43/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0048\n",
      "Epoch 43: val_accuracy did not improve from 0.69167\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0058 - val_accuracy: 0.6083 - val_loss: 1.9374\n",
      "Epoch 44/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0098\n",
      "Epoch 44: val_accuracy did not improve from 0.69167\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0065 - val_accuracy: 0.6250 - val_loss: 1.9867\n",
      "Epoch 45/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0070\n",
      "Epoch 45: val_accuracy did not improve from 0.69167\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0058 - val_accuracy: 0.6250 - val_loss: 2.0308\n",
      "Epoch 46/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0043\n",
      "Epoch 46: val_accuracy did not improve from 0.69167\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0054 - val_accuracy: 0.6333 - val_loss: 2.0677\n",
      "Epoch 47/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0038\n",
      "Epoch 47: val_accuracy did not improve from 0.69167\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0042 - val_accuracy: 0.6500 - val_loss: 2.0615\n",
      "Epoch 48/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0046\n",
      "Epoch 48: val_accuracy did not improve from 0.69167\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 0.6500 - val_loss: 2.1203\n",
      "Epoch 49/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0019\n",
      "Epoch 49: val_accuracy did not improve from 0.69167\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 0.6500 - val_loss: 2.1615\n",
      "Epoch 50/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0016\n",
      "Epoch 50: val_accuracy did not improve from 0.69167\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 0.6417 - val_loss: 2.1693\n",
      "Loaded Best Model Weights.\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "Train Set Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8560    0.7357    0.7913       420\n",
      "         1.0     0.7688    0.8765    0.8191       421\n",
      "\n",
      "    accuracy                         0.8062       841\n",
      "   macro avg     0.8124    0.8061    0.8052       841\n",
      "weighted avg     0.8123    0.8062    0.8052       841\n",
      "\n",
      "Validation Set Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7018    0.6667    0.6838        60\n",
      "         1.0     0.6825    0.7167    0.6992        60\n",
      "\n",
      "    accuracy                         0.6917       120\n",
      "   macro avg     0.6921    0.6917    0.6915       120\n",
      "weighted avg     0.6921    0.6917    0.6915       120\n",
      "\n",
      "Test Set Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7765    0.5455    0.6408       121\n",
      "         1.0     0.6474    0.8417    0.7319       120\n",
      "\n",
      "    accuracy                         0.6929       241\n",
      "   macro avg     0.7120    0.6936    0.6863       241\n",
      "weighted avg     0.7122    0.6929    0.6861       241\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "FCN MODEL\n",
    "\"\"\"\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Load the final dataset\n",
    "df = pd.read_csv(\"/kaggle/input/btp-audioembeddings/audio_features_hubert.csv\")\n",
    "\n",
    "# Extract labels\n",
    "y = df[\"Sarcasm\"].values  # Labels (0: No sarcasm, 1: Sarcasm)\n",
    "\n",
    "# Extract context and utterance features\n",
    "X_context = df[[col for col in df.columns if col.startswith(\"audio_c_feature_\")]].values\n",
    "X_utterance = df[[col for col in df.columns if col.startswith(\"audio_u_feature_\")]].values\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "X_context = np.array(X_context, dtype=np.float32)\n",
    "X_utterance = np.array(X_utterance, dtype=np.float32)\n",
    "y = np.array(y, dtype=np.float32)\n",
    "\n",
    "# First, split into train (70%) and temp (30%) \n",
    "Xc_train, Xc_temp, Xu_train, Xu_temp, y_train, y_temp = train_test_split(\n",
    "    X_context, X_utterance, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Split temp (30%) into validation (10%) and test (20%)\n",
    "Xc_val, Xc_test, Xu_val, Xu_test, y_val, y_test = train_test_split(\n",
    "    Xc_temp, Xu_temp, y_temp, test_size=2/3, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "# FCN Model for Sarcasm Detection\n",
    "input_dim = 768  # Number of features per input\n",
    "\n",
    "# Context Branch (Fully Connected Layers)\n",
    "input_context = keras.Input(shape=(input_dim,))\n",
    "context_branch = layers.Dense(128, activation=\"tanh\")(input_context)\n",
    "context_branch = layers.Dense(64, activation=\"tanh\")(context_branch)\n",
    "\n",
    "# Utterance Branch (Fully Connected Layers)\n",
    "input_utterance = keras.Input(shape=(input_dim,))\n",
    "utterance_branch = layers.Dense(128, activation=\"tanh\")(input_utterance)\n",
    "utterance_branch = layers.Dense(64, activation=\"tanh\")(utterance_branch)\n",
    "\n",
    "# Concatenation\n",
    "merged = layers.Concatenate()([context_branch, utterance_branch])\n",
    "merged = layers.Dense(64, activation=\"tanh\")(merged)\n",
    "output = layers.Dense(1, activation=\"sigmoid\")(merged)  # Sigmoid for binary classification\n",
    "\n",
    "# Define Model\n",
    "model = keras.Model(inputs=[input_context, input_utterance], outputs=output)\n",
    "model.summary()\n",
    "\n",
    "# Compile Model\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Checkpoint to save the best model based on validation accuracy\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    \"/kaggle/working/hubert_fcn_model.weights.h5\",\n",
    "    monitor=\"val_accuracy\",\n",
    "    mode=\"max\",\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train Model\n",
    "model.fit(\n",
    "    [Xc_train, Xu_train], y_train,\n",
    "    epochs=50, batch_size=32,\n",
    "    validation_data=([Xc_val, Xu_val], y_val),\n",
    "    callbacks=[checkpoint_callback]\n",
    ")\n",
    "\n",
    "# Load best model weights\n",
    "model.load_weights(\"/kaggle/working/hubert_fcn_model.weights.h5\")\n",
    "print(\"Loaded Best Model Weights.\")\n",
    "\n",
    "# Generate predictions using the best model\n",
    "y_train_pred = (model.predict([Xc_train, Xu_train]) > 0.5).astype(int)\n",
    "y_val_pred = (model.predict([Xc_val, Xu_val]) > 0.5).astype(int)\n",
    "y_test_pred = (model.predict([Xc_test, Xu_test]) > 0.5).astype(int)\n",
    "\n",
    "# Print classification reports\n",
    "print(\"Train Set Classification Report:\\n\", classification_report(y_train, y_train_pred, digits=4))\n",
    "print(\"Validation Set Classification Report:\\n\", classification_report(y_val, y_val_pred, digits=4))\n",
    "print(\"Test Set Classification Report:\\n\", classification_report(y_test, y_test_pred, digits=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Trained ON MMS Embeddings\n",
    "\n",
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T05:23:05.084273Z",
     "iopub.status.busy": "2025-03-22T05:23:05.083923Z",
     "iopub.status.idle": "2025-03-22T05:24:03.328723Z",
     "shell.execute_reply": "2025-03-22T05:24:03.327269Z",
     "shell.execute_reply.started": "2025-03-22T05:23:05.084246Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_7\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_7\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_14            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ input_layer_15            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ reshape_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)        │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ reshape_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)        │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv1d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1278</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ reshape_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv1d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1278</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ reshape_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ max_pooling1d_14          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">639</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)            │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ max_pooling1d_15          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">639</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)            │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ flatten_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">163584</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ flatten_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">163584</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ concatenate_7             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">327168</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ flatten_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">83,755,264</span> │ concatenate_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">156</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">40,092</span> │ dense_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">20,096</span> │ dense_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dense_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ dense_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">264</span> │ dense_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │ dense_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_14            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ input_layer_15            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ reshape_14 (\u001b[38;5;33mReshape\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m, \u001b[38;5;34m1\u001b[0m)        │              \u001b[38;5;34m0\u001b[0m │ input_layer_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ reshape_15 (\u001b[38;5;33mReshape\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m, \u001b[38;5;34m1\u001b[0m)        │              \u001b[38;5;34m0\u001b[0m │ input_layer_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv1d_14 (\u001b[38;5;33mConv1D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1278\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │          \u001b[38;5;34m1,024\u001b[0m │ reshape_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv1d_15 (\u001b[38;5;33mConv1D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1278\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │          \u001b[38;5;34m1,024\u001b[0m │ reshape_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ max_pooling1d_14          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m639\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ conv1d_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)            │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ max_pooling1d_15          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m639\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ conv1d_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)            │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ flatten_14 (\u001b[38;5;33mFlatten\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m163584\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ max_pooling1d_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ flatten_15 (\u001b[38;5;33mFlatten\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m163584\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ max_pooling1d_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ concatenate_7             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m327168\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ flatten_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ flatten_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │     \u001b[38;5;34m83,755,264\u001b[0m │ concatenate_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m156\u001b[0m)            │         \u001b[38;5;34m40,092\u001b[0m │ dense_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m20,096\u001b[0m │ dense_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │          \u001b[38;5;34m8,256\u001b[0m │ dense_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │          \u001b[38;5;34m2,080\u001b[0m │ dense_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_18 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │            \u001b[38;5;34m264\u001b[0m │ dense_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_19 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │              \u001b[38;5;34m9\u001b[0m │ dense_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">83,828,109</span> (319.78 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m83,828,109\u001b[0m (319.78 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">83,828,109</span> (319.78 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m83,828,109\u001b[0m (319.78 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - accuracy: 0.5342 - loss: 0.7621\n",
      "Epoch 1: val_accuracy improved from -inf to 0.62500, saving model to /kaggle/working/mms_cnn_model.weights.h5\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 312ms/step - accuracy: 0.5346 - loss: 0.7616 - val_accuracy: 0.6250 - val_loss: 0.6777\n",
      "Epoch 2/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5487 - loss: 0.6851\n",
      "Epoch 2: val_accuracy did not improve from 0.62500\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5488 - loss: 0.6850 - val_accuracy: 0.5083 - val_loss: 0.6717\n",
      "Epoch 3/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6034 - loss: 0.6537\n",
      "Epoch 3: val_accuracy did not improve from 0.62500\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6029 - loss: 0.6547 - val_accuracy: 0.5917 - val_loss: 0.6563\n",
      "Epoch 4/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6015 - loss: 0.6609\n",
      "Epoch 4: val_accuracy did not improve from 0.62500\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5995 - loss: 0.6621 - val_accuracy: 0.5500 - val_loss: 0.6848\n",
      "Epoch 5/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5007 - loss: 0.6978\n",
      "Epoch 5: val_accuracy did not improve from 0.62500\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5048 - loss: 0.6961 - val_accuracy: 0.6250 - val_loss: 0.6614\n",
      "Epoch 6/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6124 - loss: 0.6536\n",
      "Epoch 6: val_accuracy did not improve from 0.62500\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6106 - loss: 0.6542 - val_accuracy: 0.5917 - val_loss: 0.6567\n",
      "Epoch 7/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6265 - loss: 0.6508\n",
      "Epoch 7: val_accuracy did not improve from 0.62500\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6252 - loss: 0.6516 - val_accuracy: 0.5917 - val_loss: 0.6563\n",
      "Epoch 8/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6023 - loss: 0.6585\n",
      "Epoch 8: val_accuracy did not improve from 0.62500\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6025 - loss: 0.6582 - val_accuracy: 0.6000 - val_loss: 0.6532\n",
      "Epoch 9/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6398 - loss: 0.6370\n",
      "Epoch 9: val_accuracy did not improve from 0.62500\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6380 - loss: 0.6379 - val_accuracy: 0.6083 - val_loss: 0.6559\n",
      "Epoch 10/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6311 - loss: 0.6170\n",
      "Epoch 10: val_accuracy did not improve from 0.62500\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6293 - loss: 0.6194 - val_accuracy: 0.5917 - val_loss: 0.6663\n",
      "Epoch 11/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6179 - loss: 0.6446\n",
      "Epoch 11: val_accuracy improved from 0.62500 to 0.65000, saving model to /kaggle/working/mms_cnn_model.weights.h5\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - accuracy: 0.6179 - loss: 0.6446 - val_accuracy: 0.6500 - val_loss: 0.6651\n",
      "Epoch 12/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6189 - loss: 0.6453\n",
      "Epoch 12: val_accuracy did not improve from 0.65000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6201 - loss: 0.6449 - val_accuracy: 0.5167 - val_loss: 0.7398\n",
      "Epoch 13/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5789 - loss: 0.6679\n",
      "Epoch 13: val_accuracy did not improve from 0.65000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5798 - loss: 0.6674 - val_accuracy: 0.6083 - val_loss: 0.6777\n",
      "Epoch 14/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5681 - loss: 0.6480\n",
      "Epoch 14: val_accuracy did not improve from 0.65000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5709 - loss: 0.6487 - val_accuracy: 0.6000 - val_loss: 0.6622\n",
      "Epoch 15/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6041 - loss: 0.6548\n",
      "Epoch 15: val_accuracy did not improve from 0.65000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6060 - loss: 0.6538 - val_accuracy: 0.6333 - val_loss: 0.6490\n",
      "Epoch 16/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5940 - loss: 0.6571\n",
      "Epoch 16: val_accuracy did not improve from 0.65000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5942 - loss: 0.6559 - val_accuracy: 0.5917 - val_loss: 0.6544\n",
      "Epoch 17/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6279 - loss: 0.6369\n",
      "Epoch 17: val_accuracy did not improve from 0.65000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6288 - loss: 0.6367 - val_accuracy: 0.6083 - val_loss: 0.6542\n",
      "Epoch 18/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5771 - loss: 0.6613\n",
      "Epoch 18: val_accuracy did not improve from 0.65000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5772 - loss: 0.6605 - val_accuracy: 0.5667 - val_loss: 0.6657\n",
      "Epoch 19/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5701 - loss: 0.6531\n",
      "Epoch 19: val_accuracy did not improve from 0.65000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5728 - loss: 0.6530 - val_accuracy: 0.5917 - val_loss: 0.6649\n",
      "Epoch 20/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6333 - loss: 0.6243\n",
      "Epoch 20: val_accuracy improved from 0.65000 to 0.65833, saving model to /kaggle/working/mms_cnn_model.weights.h5\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - accuracy: 0.6335 - loss: 0.6243 - val_accuracy: 0.6583 - val_loss: 0.6475\n",
      "Epoch 21/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5985 - loss: 0.6322\n",
      "Epoch 21: val_accuracy did not improve from 0.65833\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5993 - loss: 0.6322 - val_accuracy: 0.6000 - val_loss: 0.6646\n",
      "Epoch 22/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6295 - loss: 0.6263\n",
      "Epoch 22: val_accuracy did not improve from 0.65833\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6289 - loss: 0.6283 - val_accuracy: 0.5167 - val_loss: 0.7047\n",
      "Epoch 23/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6343 - loss: 0.6356\n",
      "Epoch 23: val_accuracy did not improve from 0.65833\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6353 - loss: 0.6350 - val_accuracy: 0.5750 - val_loss: 0.6572\n",
      "Epoch 24/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6014 - loss: 0.6454\n",
      "Epoch 24: val_accuracy did not improve from 0.65833\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6032 - loss: 0.6439 - val_accuracy: 0.6000 - val_loss: 0.6595\n",
      "Epoch 25/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6197 - loss: 0.6302\n",
      "Epoch 25: val_accuracy did not improve from 0.65833\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6185 - loss: 0.6312 - val_accuracy: 0.6000 - val_loss: 0.6655\n",
      "Epoch 26/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5411 - loss: 0.6486\n",
      "Epoch 26: val_accuracy did not improve from 0.65833\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5460 - loss: 0.6493 - val_accuracy: 0.6417 - val_loss: 0.6566\n",
      "Epoch 27/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6659 - loss: 0.6334\n",
      "Epoch 27: val_accuracy did not improve from 0.65833\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6662 - loss: 0.6323 - val_accuracy: 0.6250 - val_loss: 0.6583\n",
      "Epoch 28/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6744 - loss: 0.5959\n",
      "Epoch 28: val_accuracy did not improve from 0.65833\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6741 - loss: 0.5964 - val_accuracy: 0.5667 - val_loss: 0.7498\n",
      "Epoch 29/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6335 - loss: 0.6502\n",
      "Epoch 29: val_accuracy did not improve from 0.65833\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6365 - loss: 0.6484 - val_accuracy: 0.6167 - val_loss: 0.6644\n",
      "Epoch 30/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6947 - loss: 0.6024\n",
      "Epoch 30: val_accuracy did not improve from 0.65833\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6910 - loss: 0.6045 - val_accuracy: 0.6167 - val_loss: 0.6475\n",
      "Epoch 31/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6328 - loss: 0.6237\n",
      "Epoch 31: val_accuracy did not improve from 0.65833\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6367 - loss: 0.6221 - val_accuracy: 0.6333 - val_loss: 0.6805\n",
      "Epoch 32/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6809 - loss: 0.5980\n",
      "Epoch 32: val_accuracy did not improve from 0.65833\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6799 - loss: 0.5990 - val_accuracy: 0.6083 - val_loss: 0.6441\n",
      "Epoch 33/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6157 - loss: 0.6262\n",
      "Epoch 33: val_accuracy did not improve from 0.65833\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6179 - loss: 0.6264 - val_accuracy: 0.5917 - val_loss: 0.6457\n",
      "Epoch 34/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7013 - loss: 0.5983\n",
      "Epoch 34: val_accuracy did not improve from 0.65833\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6993 - loss: 0.5988 - val_accuracy: 0.5833 - val_loss: 0.6747\n",
      "Epoch 35/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6331 - loss: 0.6336\n",
      "Epoch 35: val_accuracy did not improve from 0.65833\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6353 - loss: 0.6324 - val_accuracy: 0.5833 - val_loss: 0.6672\n",
      "Epoch 36/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6358 - loss: 0.6212\n",
      "Epoch 36: val_accuracy did not improve from 0.65833\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6383 - loss: 0.6209 - val_accuracy: 0.6167 - val_loss: 0.6596\n",
      "Epoch 37/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7369 - loss: 0.5731\n",
      "Epoch 37: val_accuracy did not improve from 0.65833\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7329 - loss: 0.5751 - val_accuracy: 0.6417 - val_loss: 0.6447\n",
      "Epoch 38/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6948 - loss: 0.5668\n",
      "Epoch 38: val_accuracy did not improve from 0.65833\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6949 - loss: 0.5685 - val_accuracy: 0.6083 - val_loss: 0.6342\n",
      "Epoch 39/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6878 - loss: 0.5752\n",
      "Epoch 39: val_accuracy did not improve from 0.65833\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6866 - loss: 0.5769 - val_accuracy: 0.5667 - val_loss: 0.6992\n",
      "Epoch 40/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6445 - loss: 0.6234\n",
      "Epoch 40: val_accuracy did not improve from 0.65833\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6468 - loss: 0.6212 - val_accuracy: 0.6417 - val_loss: 0.6729\n",
      "Epoch 41/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6888 - loss: 0.6095\n",
      "Epoch 41: val_accuracy did not improve from 0.65833\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.6844 - loss: 0.6123 - val_accuracy: 0.6167 - val_loss: 0.6461\n",
      "Epoch 42/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6716 - loss: 0.6191\n",
      "Epoch 42: val_accuracy did not improve from 0.65833\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6704 - loss: 0.6187 - val_accuracy: 0.6583 - val_loss: 0.6386\n",
      "Epoch 43/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7102 - loss: 0.5682\n",
      "Epoch 43: val_accuracy did not improve from 0.65833\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7080 - loss: 0.5697 - val_accuracy: 0.6417 - val_loss: 0.6799\n",
      "Epoch 44/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6413 - loss: 0.6114\n",
      "Epoch 44: val_accuracy did not improve from 0.65833\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6445 - loss: 0.6098 - val_accuracy: 0.6000 - val_loss: 0.6447\n",
      "Epoch 45/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7013 - loss: 0.5729\n",
      "Epoch 45: val_accuracy did not improve from 0.65833\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6983 - loss: 0.5755 - val_accuracy: 0.6167 - val_loss: 0.6332\n",
      "Epoch 46/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7110 - loss: 0.5741\n",
      "Epoch 46: val_accuracy did not improve from 0.65833\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7103 - loss: 0.5748 - val_accuracy: 0.6333 - val_loss: 0.6378\n",
      "Epoch 47/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7013 - loss: 0.5502\n",
      "Epoch 47: val_accuracy did not improve from 0.65833\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7012 - loss: 0.5522 - val_accuracy: 0.6000 - val_loss: 0.7035\n",
      "Epoch 48/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6808 - loss: 0.6235\n",
      "Epoch 48: val_accuracy did not improve from 0.65833\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6813 - loss: 0.6205 - val_accuracy: 0.6417 - val_loss: 0.6354\n",
      "Epoch 49/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6917 - loss: 0.5607\n",
      "Epoch 49: val_accuracy improved from 0.65833 to 0.66667, saving model to /kaggle/working/mms_cnn_model.weights.h5\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - accuracy: 0.6923 - loss: 0.5626 - val_accuracy: 0.6667 - val_loss: 0.6581\n",
      "Epoch 50/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6907 - loss: 0.5952\n",
      "Epoch 50: val_accuracy did not improve from 0.66667\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6921 - loss: 0.5931 - val_accuracy: 0.5833 - val_loss: 0.7875\n",
      "Loaded Best Model Weights.\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step\n",
      "Train Set Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6747    0.7952    0.7301       420\n",
      "         1.0     0.7514    0.6176    0.6780       421\n",
      "\n",
      "    accuracy                         0.7063       841\n",
      "   macro avg     0.7131    0.7064    0.7040       841\n",
      "weighted avg     0.7131    0.7063    0.7040       841\n",
      "\n",
      "Validation Set Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6389    0.7667    0.6970        60\n",
      "         1.0     0.7083    0.5667    0.6296        60\n",
      "\n",
      "    accuracy                         0.6667       120\n",
      "   macro avg     0.6736    0.6667    0.6633       120\n",
      "weighted avg     0.6736    0.6667    0.6633       120\n",
      "\n",
      "Test Set Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6615    0.7107    0.6853       121\n",
      "         1.0     0.6847    0.6333    0.6580       120\n",
      "\n",
      "    accuracy                         0.6722       241\n",
      "   macro avg     0.6731    0.6720    0.6716       241\n",
      "weighted avg     0.6731    0.6722    0.6717       241\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "CNN MODEL\n",
    "\"\"\"\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Load the final dataset\n",
    "df = pd.read_csv(\"/kaggle/input/btp-audioembeddings/audio_features_mms.csv\")\n",
    "\n",
    "# Extract labels\n",
    "y = df[\"Sarcasm\"].values  # Labels (0: No sarcasm, 1: Sarcasm)\n",
    "\n",
    "# Extract context features (from csv1_)\n",
    "X_context = df[[col for col in df.columns if col.startswith(\"audio_c_feature_\")]].values\n",
    "\n",
    "# Extract utterance features (from csv2_)\n",
    "X_utterance = df[[col for col in df.columns if col.startswith(\"audio_u_feature_\")]].values\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "X_context = np.array(X_context, dtype=np.float32)\n",
    "X_utterance = np.array(X_utterance, dtype=np.float32)\n",
    "y = np.array(y, dtype=np.float32)\n",
    "\n",
    "# First, split into train (70%) and temp (30%) \n",
    "Xc_train, Xc_temp, Xu_train, Xu_temp, y_train, y_temp = train_test_split(\n",
    "    X_context, X_utterance, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Split temp (30%) into validation (10%) and test (20%)\n",
    "Xc_val, Xc_test, Xu_val, Xu_test, y_val, y_test = train_test_split(\n",
    "    Xc_temp, Xu_temp, y_temp, test_size=2/3, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "# CNN Model for Sarcasm Detection\n",
    "input_dim = 1280  # Number of features per input\n",
    "\n",
    "# Context Branch\n",
    "input_context = keras.Input(shape=(input_dim,))\n",
    "context_branch = layers.Reshape((input_dim, 1))(input_context)\n",
    "context_branch = layers.Conv1D(filters=256, kernel_size=3, activation=\"relu\")(context_branch)\n",
    "context_branch = layers.MaxPooling1D(pool_size=2)(context_branch)\n",
    "context_branch = layers.Flatten()(context_branch)\n",
    "\n",
    "# Utterance Branch\n",
    "input_utterance = keras.Input(shape=(input_dim,))\n",
    "utterance_branch = layers.Reshape((input_dim, 1))(input_utterance)\n",
    "utterance_branch = layers.Conv1D(filters=256, kernel_size=3, activation=\"relu\")(utterance_branch)\n",
    "utterance_branch = layers.MaxPooling1D(pool_size=2)(utterance_branch)\n",
    "utterance_branch = layers.Flatten()(utterance_branch)\n",
    "\n",
    "# Concatenation\n",
    "merged = layers.Concatenate()([context_branch, utterance_branch])\n",
    "merged = layers.Dense(256, activation=\"relu\")(merged)\n",
    "merged = layers.Dense(156, activation=\"relu\")(merged)\n",
    "merged = layers.Dense(128, activation=\"relu\")(merged)\n",
    "merged = layers.Dense(64, activation=\"relu\")(merged)\n",
    "merged = layers.Dense(32, activation=\"relu\")(merged)\n",
    "merged = layers.Dense(8, activation=\"relu\")(merged)\n",
    "output = layers.Dense(1, activation=\"sigmoid\")(merged)  # Sigmoid for binary classification\n",
    "\n",
    "# Define Model\n",
    "model = keras.Model(inputs=[input_context, input_utterance], outputs=output)\n",
    "model.summary()\n",
    "\n",
    "# Compile Model\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Checkpoint to save the best model based on validation accuracy\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    \"/kaggle/working/mms_cnn_model.weights.h5\",\n",
    "    monitor=\"val_accuracy\",  # Monitor validation accuracy\n",
    "    mode=\"max\",  # Save when val_accuracy is maximum\n",
    "    save_best_only=True,  # Keep only the best weights\n",
    "    save_weights_only=True,  # Don't save full model\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train Model\n",
    "model.fit(\n",
    "    [Xc_train, Xu_train], y_train,\n",
    "    epochs=50, batch_size=32,\n",
    "    validation_data=([Xc_val, Xu_val], y_val),  # Use validation set\n",
    "    callbacks=[checkpoint_callback]\n",
    ")\n",
    "\n",
    "# Load best model weights\n",
    "model.load_weights(\"/kaggle/working/mms_cnn_model.weights.h5\")\n",
    "print(\"Loaded Best Model Weights.\")\n",
    "\n",
    "# Generate predictions using the best model\n",
    "y_train_pred = (model.predict([Xc_train, Xu_train]) > 0.5).astype(int)\n",
    "y_val_pred = (model.predict([Xc_val, Xu_val]) > 0.5).astype(int)\n",
    "y_test_pred = (model.predict([Xc_test, Xu_test]) > 0.5).astype(int)\n",
    "\n",
    "# Print classification reports for all sets\n",
    "print(\"Train Set Classification Report:\\n\", classification_report(y_train, y_train_pred,digits=4))\n",
    "print(\"Validation Set Classification Report:\\n\", classification_report(y_val, y_val_pred,digits=4))\n",
    "print(\"Test Set Classification Report:\\n\", classification_report(y_test, y_test_pred,digits=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T05:26:41.312437Z",
     "iopub.status.busy": "2025-03-22T05:26:41.312104Z",
     "iopub.status.idle": "2025-03-22T05:26:53.697037Z",
     "shell.execute_reply": "2025-03-22T05:26:53.695990Z",
     "shell.execute_reply.started": "2025-03-22T05:26:41.312411Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_11\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_11\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_22            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ input_layer_23            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">163,968</span> │ input_layer_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_42 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">163,968</span> │ input_layer_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dense_38[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_43 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dense_42[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_40 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ dense_39[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_44 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ dense_43[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">264</span> │ dense_40[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_45 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">264</span> │ dense_44[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ concatenate_11            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_41[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ dense_45[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_46 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,088</span> │ concatenate_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_47 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ dense_46[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_22            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ input_layer_23            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_38 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m163,968\u001b[0m │ input_layer_22[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_42 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m163,968\u001b[0m │ input_layer_23[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_39 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │          \u001b[38;5;34m8,256\u001b[0m │ dense_38[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_43 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │          \u001b[38;5;34m8,256\u001b[0m │ dense_42[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_40 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │          \u001b[38;5;34m2,080\u001b[0m │ dense_39[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_44 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │          \u001b[38;5;34m2,080\u001b[0m │ dense_43[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_41 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │            \u001b[38;5;34m264\u001b[0m │ dense_40[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_45 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │            \u001b[38;5;34m264\u001b[0m │ dense_44[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ concatenate_11            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ dense_41[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ dense_45[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_46 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │          \u001b[38;5;34m1,088\u001b[0m │ concatenate_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_47 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m65\u001b[0m │ dense_46[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">350,289</span> (1.34 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m350,289\u001b[0m (1.34 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">350,289</span> (1.34 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m350,289\u001b[0m (1.34 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.4931 - loss: 0.6886\n",
      "Epoch 1: val_accuracy improved from -inf to 0.58333, saving model to /kaggle/working/mms_fcn_model.weights.h5\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 68ms/step - accuracy: 0.4948 - loss: 0.6884 - val_accuracy: 0.5833 - val_loss: 0.6713\n",
      "Epoch 2/50\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5979 - loss: 0.6677 \n",
      "Epoch 2: val_accuracy did not improve from 0.58333\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5974 - loss: 0.6682 - val_accuracy: 0.5333 - val_loss: 0.6934\n",
      "Epoch 3/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5206 - loss: 0.6932 \n",
      "Epoch 3: val_accuracy did not improve from 0.58333\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5211 - loss: 0.6930 - val_accuracy: 0.5750 - val_loss: 0.6709\n",
      "Epoch 4/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5764 - loss: 0.6616 \n",
      "Epoch 4: val_accuracy improved from 0.58333 to 0.59167, saving model to /kaggle/working/mms_fcn_model.weights.h5\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5771 - loss: 0.6616 - val_accuracy: 0.5917 - val_loss: 0.6697\n",
      "Epoch 5/50\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5755 - loss: 0.6666 \n",
      "Epoch 5: val_accuracy did not improve from 0.59167\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5755 - loss: 0.6666 - val_accuracy: 0.5917 - val_loss: 0.6632\n",
      "Epoch 6/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5625 - loss: 0.6826\n",
      "Epoch 6: val_accuracy did not improve from 0.59167\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5982 - loss: 0.6580 - val_accuracy: 0.5750 - val_loss: 0.6555\n",
      "Epoch 7/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6108 - loss: 0.6516 \n",
      "Epoch 7: val_accuracy improved from 0.59167 to 0.62500, saving model to /kaggle/working/mms_fcn_model.weights.h5\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6108 - loss: 0.6517 - val_accuracy: 0.6250 - val_loss: 0.6499\n",
      "Epoch 8/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6250 - loss: 0.6312\n",
      "Epoch 8: val_accuracy did not improve from 0.62500\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6270 - loss: 0.6353 - val_accuracy: 0.5833 - val_loss: 0.6556\n",
      "Epoch 9/50\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6101 - loss: 0.6523 \n",
      "Epoch 9: val_accuracy did not improve from 0.62500\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6106 - loss: 0.6521 - val_accuracy: 0.6250 - val_loss: 0.6475\n",
      "Epoch 10/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5975 - loss: 0.6463 \n",
      "Epoch 10: val_accuracy did not improve from 0.62500\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5981 - loss: 0.6461 - val_accuracy: 0.5750 - val_loss: 0.6807\n",
      "Epoch 11/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5312 - loss: 0.6369\n",
      "Epoch 11: val_accuracy did not improve from 0.62500\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6092 - loss: 0.6402 - val_accuracy: 0.5917 - val_loss: 0.6517\n",
      "Epoch 12/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6088 - loss: 0.6477 \n",
      "Epoch 12: val_accuracy improved from 0.62500 to 0.64167, saving model to /kaggle/working/mms_fcn_model.weights.h5\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6095 - loss: 0.6475 - val_accuracy: 0.6417 - val_loss: 0.6585\n",
      "Epoch 13/50\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6320 - loss: 0.6249 \n",
      "Epoch 13: val_accuracy did not improve from 0.64167\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6313 - loss: 0.6257 - val_accuracy: 0.5833 - val_loss: 0.6521\n",
      "Epoch 14/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6411 - loss: 0.6241 \n",
      "Epoch 14: val_accuracy did not improve from 0.64167\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6411 - loss: 0.6242 - val_accuracy: 0.6000 - val_loss: 0.6588\n",
      "Epoch 15/50\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6168 - loss: 0.6402 \n",
      "Epoch 15: val_accuracy did not improve from 0.64167\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6193 - loss: 0.6391 - val_accuracy: 0.6000 - val_loss: 0.6684\n",
      "Epoch 16/50\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5557 - loss: 0.6748 \n",
      "Epoch 16: val_accuracy did not improve from 0.64167\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5578 - loss: 0.6739 - val_accuracy: 0.5333 - val_loss: 0.7021\n",
      "Epoch 17/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4062 - loss: 0.7762\n",
      "Epoch 17: val_accuracy did not improve from 0.64167\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6119 - loss: 0.6498 - val_accuracy: 0.6250 - val_loss: 0.6470\n",
      "Epoch 18/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6903 - loss: 0.6100 \n",
      "Epoch 18: val_accuracy did not improve from 0.64167\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6891 - loss: 0.6104 - val_accuracy: 0.6417 - val_loss: 0.6434\n",
      "Epoch 19/50\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6088 - loss: 0.6418 \n",
      "Epoch 19: val_accuracy did not improve from 0.64167\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6092 - loss: 0.6410 - val_accuracy: 0.6333 - val_loss: 0.6508\n",
      "Epoch 20/50\n",
      "\u001b[1m21/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6526 - loss: 0.6299 \n",
      "Epoch 20: val_accuracy did not improve from 0.64167\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6484 - loss: 0.6323 - val_accuracy: 0.5917 - val_loss: 0.6478\n",
      "Epoch 21/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5982 - loss: 0.6560 \n",
      "Epoch 21: val_accuracy did not improve from 0.64167\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5989 - loss: 0.6557 - val_accuracy: 0.5833 - val_loss: 0.6515\n",
      "Epoch 22/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6013 - loss: 0.6329 \n",
      "Epoch 22: val_accuracy did not improve from 0.64167\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6019 - loss: 0.6330 - val_accuracy: 0.6000 - val_loss: 0.6653\n",
      "Epoch 23/50\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6774 - loss: 0.6093 \n",
      "Epoch 23: val_accuracy did not improve from 0.64167\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6751 - loss: 0.6100 - val_accuracy: 0.6250 - val_loss: 0.6419\n",
      "Epoch 24/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6707 - loss: 0.6005 \n",
      "Epoch 24: val_accuracy did not improve from 0.64167\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6702 - loss: 0.6008 - val_accuracy: 0.6167 - val_loss: 0.6533\n",
      "Epoch 25/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6681 - loss: 0.5966 \n",
      "Epoch 25: val_accuracy did not improve from 0.64167\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6677 - loss: 0.5969 - val_accuracy: 0.5917 - val_loss: 0.6587\n",
      "Epoch 26/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6128 - loss: 0.6279 \n",
      "Epoch 26: val_accuracy did not improve from 0.64167\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6141 - loss: 0.6273 - val_accuracy: 0.6333 - val_loss: 0.6371\n",
      "Epoch 27/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6575 - loss: 0.6109 \n",
      "Epoch 27: val_accuracy did not improve from 0.64167\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6571 - loss: 0.6109 - val_accuracy: 0.5667 - val_loss: 0.6840\n",
      "Epoch 28/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6985 - loss: 0.5958 \n",
      "Epoch 28: val_accuracy did not improve from 0.64167\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6982 - loss: 0.5956 - val_accuracy: 0.5833 - val_loss: 0.6708\n",
      "Epoch 29/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6756 - loss: 0.5984 \n",
      "Epoch 29: val_accuracy did not improve from 0.64167\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6755 - loss: 0.5986 - val_accuracy: 0.6417 - val_loss: 0.6467\n",
      "Epoch 30/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7812 - loss: 0.5657\n",
      "Epoch 30: val_accuracy did not improve from 0.64167\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6381 - loss: 0.6313 - val_accuracy: 0.6250 - val_loss: 0.6506\n",
      "Epoch 31/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6875 - loss: 0.5997 \n",
      "Epoch 31: val_accuracy did not improve from 0.64167\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6866 - loss: 0.6003 - val_accuracy: 0.6250 - val_loss: 0.6488\n",
      "Epoch 32/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6925 - loss: 0.6062 \n",
      "Epoch 32: val_accuracy improved from 0.64167 to 0.65000, saving model to /kaggle/working/mms_fcn_model.weights.h5\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6913 - loss: 0.6061 - val_accuracy: 0.6500 - val_loss: 0.6383\n",
      "Epoch 33/50\n",
      "\u001b[1m 1/27\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6875 - loss: 0.5544\n",
      "Epoch 33: val_accuracy did not improve from 0.65000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6740 - loss: 0.5882 - val_accuracy: 0.6333 - val_loss: 0.6599\n",
      "Epoch 34/50\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6448 - loss: 0.6135 \n",
      "Epoch 34: val_accuracy did not improve from 0.65000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6451 - loss: 0.6133 - val_accuracy: 0.5917 - val_loss: 0.6471\n",
      "Epoch 35/50\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7149 - loss: 0.5728 \n",
      "Epoch 35: val_accuracy did not improve from 0.65000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7134 - loss: 0.5742 - val_accuracy: 0.6500 - val_loss: 0.6405\n",
      "Epoch 36/50\n",
      "\u001b[1m24/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6554 - loss: 0.6247 \n",
      "Epoch 36: val_accuracy did not improve from 0.65000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6544 - loss: 0.6241 - val_accuracy: 0.6167 - val_loss: 0.6437\n",
      "Epoch 37/50\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6563 - loss: 0.5919 \n",
      "Epoch 37: val_accuracy did not improve from 0.65000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6552 - loss: 0.5929 - val_accuracy: 0.6000 - val_loss: 0.6367\n",
      "Epoch 38/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7180 - loss: 0.5803 \n",
      "Epoch 38: val_accuracy did not improve from 0.65000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7144 - loss: 0.5810 - val_accuracy: 0.6250 - val_loss: 0.6439\n",
      "Epoch 39/50\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7006 - loss: 0.6025 \n",
      "Epoch 39: val_accuracy did not improve from 0.65000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6996 - loss: 0.6024 - val_accuracy: 0.5917 - val_loss: 0.6623\n",
      "Epoch 40/50\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6338 - loss: 0.6448 \n",
      "Epoch 40: val_accuracy did not improve from 0.65000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6359 - loss: 0.6423 - val_accuracy: 0.5750 - val_loss: 0.6763\n",
      "Epoch 41/50\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6685 - loss: 0.5995 \n",
      "Epoch 41: val_accuracy did not improve from 0.65000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6700 - loss: 0.5987 - val_accuracy: 0.6167 - val_loss: 0.6597\n",
      "Epoch 42/50\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6816 - loss: 0.5933 \n",
      "Epoch 42: val_accuracy did not improve from 0.65000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6824 - loss: 0.5930 - val_accuracy: 0.6417 - val_loss: 0.6416\n",
      "Epoch 43/50\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6274 - loss: 0.6320 \n",
      "Epoch 43: val_accuracy did not improve from 0.65000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6314 - loss: 0.6287 - val_accuracy: 0.6167 - val_loss: 0.6618\n",
      "Epoch 44/50\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6715 - loss: 0.5756 \n",
      "Epoch 44: val_accuracy did not improve from 0.65000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6719 - loss: 0.5761 - val_accuracy: 0.6250 - val_loss: 0.6801\n",
      "Epoch 45/50\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6942 - loss: 0.5852 \n",
      "Epoch 45: val_accuracy did not improve from 0.65000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6939 - loss: 0.5852 - val_accuracy: 0.6083 - val_loss: 0.6504\n",
      "Epoch 46/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7141 - loss: 0.5548 \n",
      "Epoch 46: val_accuracy did not improve from 0.65000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7130 - loss: 0.5556 - val_accuracy: 0.6250 - val_loss: 0.6411\n",
      "Epoch 47/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6946 - loss: 0.5659 \n",
      "Epoch 47: val_accuracy did not improve from 0.65000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6947 - loss: 0.5660 - val_accuracy: 0.6250 - val_loss: 0.6898\n",
      "Epoch 48/50\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6707 - loss: 0.6032 \n",
      "Epoch 48: val_accuracy did not improve from 0.65000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6710 - loss: 0.6022 - val_accuracy: 0.6333 - val_loss: 0.6486\n",
      "Epoch 49/50\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7032 - loss: 0.5905 \n",
      "Epoch 49: val_accuracy did not improve from 0.65000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7035 - loss: 0.5900 - val_accuracy: 0.5833 - val_loss: 0.7135\n",
      "Epoch 50/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7151 - loss: 0.5782 \n",
      "Epoch 50: val_accuracy improved from 0.65000 to 0.66667, saving model to /kaggle/working/mms_fcn_model.weights.h5\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7147 - loss: 0.5782 - val_accuracy: 0.6667 - val_loss: 0.6415\n",
      "Loaded Best Model Weights.\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Train Set Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6761    0.8000    0.7328       420\n",
      "         1.0     0.7558    0.6176    0.6797       421\n",
      "\n",
      "    accuracy                         0.7087       841\n",
      "   macro avg     0.7159    0.7088    0.7063       841\n",
      "weighted avg     0.7160    0.7087    0.7062       841\n",
      "\n",
      "Validation Set Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6316    0.8000    0.7059        60\n",
      "         1.0     0.7273    0.5333    0.6154        60\n",
      "\n",
      "    accuracy                         0.6667       120\n",
      "   macro avg     0.6794    0.6667    0.6606       120\n",
      "weighted avg     0.6794    0.6667    0.6606       120\n",
      "\n",
      "Test Set Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6769    0.7273    0.7012       121\n",
      "         1.0     0.7027    0.6500    0.6753       120\n",
      "\n",
      "    accuracy                         0.6888       241\n",
      "   macro avg     0.6898    0.6886    0.6883       241\n",
      "weighted avg     0.6898    0.6888    0.6883       241\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "FCN MODEL\n",
    "\"\"\"\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Load the final dataset\n",
    "df = pd.read_csv(\"/kaggle/input/btp-audioembeddings/audio_features_mms.csv\")\n",
    "\n",
    "# Extract labels\n",
    "y = df[\"Sarcasm\"].values  # Labels (0: No sarcasm, 1: Sarcasm)\n",
    "\n",
    "# Extract context and utterance features\n",
    "X_context = df[[col for col in df.columns if col.startswith(\"audio_c_feature_\")]].values\n",
    "X_utterance = df[[col for col in df.columns if col.startswith(\"audio_u_feature_\")]].values\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "X_context = np.array(X_context, dtype=np.float32)\n",
    "X_utterance = np.array(X_utterance, dtype=np.float32)\n",
    "y = np.array(y, dtype=np.float32)\n",
    "\n",
    "# First, split into train (70%) and temp (30%) \n",
    "Xc_train, Xc_temp, Xu_train, Xu_temp, y_train, y_temp = train_test_split(\n",
    "    X_context, X_utterance, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Split temp (30%) into validation (10%) and test (20%)\n",
    "Xc_val, Xc_test, Xu_val, Xu_test, y_val, y_test = train_test_split(\n",
    "    Xc_temp, Xu_temp, y_temp, test_size=2/3, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "# FCN Model for Sarcasm Detection\n",
    "input_dim = 1280  # Number of features per input\n",
    "\n",
    "# Context Branch (Fully Connected Layers)\n",
    "input_context = keras.Input(shape=(input_dim,))\n",
    "context_branch = layers.Dense(128, activation=\"relu\")(input_context)\n",
    "context_branch = layers.Dense(64, activation=\"relu\")(context_branch)\n",
    "context_branch = layers.Dense(32, activation=\"relu\")(context_branch)\n",
    "context_branch = layers.Dense(8, activation=\"relu\")(context_branch)\n",
    "\n",
    "\n",
    "# Utterance Branch (Fully Connected Layers)\n",
    "input_utterance = keras.Input(shape=(input_dim,))\n",
    "utterance_branch = layers.Dense(128, activation=\"relu\")(input_utterance)\n",
    "utterance_branch = layers.Dense(64, activation=\"relu\")(utterance_branch)\n",
    "utterance_branch = layers.Dense(32, activation=\"relu\")(utterance_branch)\n",
    "utterance_branch = layers.Dense(8, activation=\"relu\")(utterance_branch)\n",
    "\n",
    "# Concatenation\n",
    "merged = layers.Concatenate()([context_branch, utterance_branch])\n",
    "merged = layers.Dense(64, activation=\"relu\")(merged)\n",
    "output = layers.Dense(1, activation=\"sigmoid\")(merged)  # Sigmoid for binary classification\n",
    "\n",
    "# Define Model\n",
    "model = keras.Model(inputs=[input_context, input_utterance], outputs=output)\n",
    "model.summary()\n",
    "\n",
    "# Compile Model\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Checkpoint to save the best model based on validation accuracy\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    \"/kaggle/working/mms_fcn_model.weights.h5\",\n",
    "    monitor=\"val_accuracy\",\n",
    "    mode=\"max\",\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train Model\n",
    "model.fit(\n",
    "    [Xc_train, Xu_train], y_train,\n",
    "    epochs=50, batch_size=32,\n",
    "    validation_data=([Xc_val, Xu_val], y_val),\n",
    "    callbacks=[checkpoint_callback]\n",
    ")\n",
    "\n",
    "# Load best model weights\n",
    "model.load_weights(\"/kaggle/working/mms_fcn_model.weights.h5\")\n",
    "print(\"Loaded Best Model Weights.\")\n",
    "\n",
    "# Generate predictions using the best model\n",
    "y_train_pred = (model.predict([Xc_train, Xu_train]) > 0.5).astype(int)\n",
    "y_val_pred = (model.predict([Xc_val, Xu_val]) > 0.5).astype(int)\n",
    "y_test_pred = (model.predict([Xc_test, Xu_test]) > 0.5).astype(int)\n",
    "\n",
    "# Print classification reports\n",
    "print(\"Train Set Classification Report:\\n\", classification_report(y_train, y_train_pred, digits=4))\n",
    "print(\"Validation Set Classification Report:\\n\", classification_report(y_val, y_val_pred, digits=4))\n",
    "print(\"Test Set Classification Report:\\n\", classification_report(y_test, y_test_pred, digits=4))\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6848937,
     "sourceId": 11120102,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

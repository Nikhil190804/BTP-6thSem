{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fde7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"/content/audio_features_whisper.csv\")\n",
    "\n",
    "# Extract labels\n",
    "y = df[\"Sarcasm\"].values  # 0 = No sarcasm, 1 = Sarcasm\n",
    "\n",
    "# Extract features\n",
    "X_context = df[[col for col in df.columns if col.startswith(\"audio_c_feature_\")]].values\n",
    "X_utterance = df[[col for col in df.columns if col.startswith(\"audio_u_feature_\")]].values\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_context = scaler.fit_transform(X_context)\n",
    "X_utterance = scaler.fit_transform(X_utterance)\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "X_context = np.array(X_context, dtype=np.float32)\n",
    "X_utterance = np.array(X_utterance, dtype=np.float32)\n",
    "y = np.array(y, dtype=np.float32)\n",
    "\n",
    "# Train-test split\n",
    "Xc_train, Xc_test, Xu_train, Xu_test, y_train, y_test = train_test_split(\n",
    "    X_context, X_utterance, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Dynamically set input dimensions\n",
    "input_dim = Xc_train.shape[1]\n",
    "\n",
    "# Context Branch (Fully Connected)\n",
    "input_context = keras.Input(shape=(input_dim,))\n",
    "context_branch = layers.Dense(512, activation=\"relu\")(input_context)\n",
    "context_branch = layers.BatchNormalization()(context_branch)\n",
    "context_branch = layers.Dense(256, activation=\"relu\")(context_branch)\n",
    "context_branch = layers.BatchNormalization()(context_branch)\n",
    "context_branch = layers.Dense(128, activation=\"relu\")(context_branch)\n",
    "context_branch = layers.Dropout(0.4)(context_branch)\n",
    "\n",
    "# Utterance Branch (Fully Connected)\n",
    "input_utterance = keras.Input(shape=(input_dim,))\n",
    "utterance_branch = layers.Dense(512, activation=\"relu\")(input_utterance)\n",
    "utterance_branch = layers.BatchNormalization()(utterance_branch)\n",
    "utterance_branch = layers.Dense(256, activation=\"relu\")(utterance_branch)\n",
    "utterance_branch = layers.BatchNormalization()(utterance_branch)\n",
    "utterance_branch = layers.Dense(128, activation=\"relu\")(utterance_branch)\n",
    "utterance_branch = layers.Dropout(0.4)(utterance_branch)\n",
    "\n",
    "# Merge both branches\n",
    "merged = layers.Concatenate()([context_branch, utterance_branch])\n",
    "merged = layers.Dense(256, activation=\"relu\")(merged)\n",
    "merged = layers.Dropout(0.3)(merged)\n",
    "merged = layers.Dense(128, activation=\"relu\")(merged)\n",
    "merged = layers.Dropout(0.3)(merged)\n",
    "merged = layers.Dense(64, activation=\"relu\")(merged)\n",
    "merged = layers.Dropout(0.2)(merged)\n",
    "output = layers.Dense(1, activation=\"sigmoid\")(merged)  # Binary classification\n",
    "\n",
    "# Define Model\n",
    "model = keras.Model(inputs=[input_context, input_utterance], outputs=output)\n",
    "model.summary()\n",
    "\n",
    "# Compile Model with Lower Learning Rate\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# Callback to save the best model\n",
    "checkpoint_path = \"best_model.h5\"\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "    checkpoint_path, monitor=\"val_accuracy\", save_best_only=True, mode=\"max\", verbose=1\n",
    ")\n",
    "\n",
    "# Train Model\n",
    "history = model.fit(\n",
    "    [Xc_train, Xu_train], y_train,\n",
    "    epochs=20, batch_size=32,\n",
    "    validation_data=([Xc_test, Xu_test], y_test),\n",
    "    callbacks=[checkpoint]\n",
    ")\n",
    "\n",
    "# Load the best model before making predictions\n",
    "best_model = keras.models.load_model(checkpoint_path)\n",
    "\n",
    "# Predictions using the best model\n",
    "y_train_pred = (best_model.predict([Xc_train, Xu_train]) > 0.5).astype(int)\n",
    "y_test_pred = (best_model.predict([Xc_test, Xu_test]) > 0.5).astype(int)\n",
    "\n",
    "# Print Accuracy\n",
    "train_acc = accuracy_score(y_train, y_train_pred)\n",
    "test_acc = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"\\n‚úÖ Train Accuracy: {train_acc:.4f}\")\n",
    "print(f\"‚úÖ Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "# Print Classification Reports\n",
    "def format_classification_report(report):\n",
    "    lines = report.split(\"\\n\")\n",
    "    formatted_lines = []\n",
    "    for line in lines:\n",
    "        parts = line.split()\n",
    "        if len(parts) == 5 and parts[0].replace('.', '', 1).isdigit():  # Ensures first part is a number (class label)\n",
    "            formatted_line = f\"{parts[0]:<10} {float(parts[1]):.4f} {float(parts[2]):.4f} {float(parts[3]):.4f} {int(parts[4])}\"\n",
    "            formatted_lines.append(formatted_line)\n",
    "        else:\n",
    "            formatted_lines.append(line)\n",
    "    return \"\\n\".join(formatted_lines)\n",
    "\n",
    "train_report = classification_report(y_train, y_train_pred, digits=4)\n",
    "test_report = classification_report(y_test, y_test_pred, digits=4)\n",
    "\n",
    "print(\"\\nTrain Set Classification Report:\\n\", format_classification_report(train_report))\n",
    "print(\"Test Set Classification Report:\\n\", format_classification_report(test_report))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd565d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"/content/audio_features_whisper.csv\")\n",
    "\n",
    "# Extract labels\n",
    "y = df[\"Sarcasm\"].values  # 0 = No sarcasm, 1 = Sarcasm\n",
    "\n",
    "# Extract features\n",
    "X_context = df[[col for col in df.columns if col.startswith(\"audio_c_feature_\")]].values\n",
    "X_utterance = df[[col for col in df.columns if col.startswith(\"audio_u_feature_\")]].values\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_context = scaler.fit_transform(X_context)\n",
    "X_utterance = scaler.fit_transform(X_utterance)\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "X_context = np.array(X_context, dtype=np.float32)\n",
    "X_utterance = np.array(X_utterance, dtype=np.float32)\n",
    "y = np.array(y, dtype=np.float32)\n",
    "\n",
    "# Train-test split\n",
    "Xc_train, Xc_test, Xu_train, Xu_test, y_train, y_test = train_test_split(\n",
    "    X_context, X_utterance, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Dynamically set input dimensions\n",
    "input_dim = Xc_train.shape[1]\n",
    "\n",
    "# Context Branch\n",
    "input_context = keras.Input(shape=(input_dim,))\n",
    "context_branch = layers.Reshape((input_dim, 1))(input_context)\n",
    "context_branch = layers.Conv1D(filters=128, kernel_size=5, activation=\"relu\")(context_branch)\n",
    "context_branch = layers.BatchNormalization()(context_branch)\n",
    "context_branch = layers.Conv1D(filters=64, kernel_size=3, activation=\"relu\")(context_branch)\n",
    "context_branch = layers.MaxPooling1D(pool_size=2)(context_branch)\n",
    "context_branch = layers.Flatten()(context_branch)\n",
    "\n",
    "# Utterance Branch\n",
    "input_utterance = keras.Input(shape=(input_dim,))\n",
    "utterance_branch = layers.Reshape((input_dim, 1))(input_utterance)\n",
    "utterance_branch = layers.Conv1D(filters=128, kernel_size=5, activation=\"relu\")(utterance_branch)\n",
    "utterance_branch = layers.BatchNormalization()(utterance_branch)\n",
    "utterance_branch = layers.Conv1D(filters=64, kernel_size=3, activation=\"relu\")(utterance_branch)\n",
    "utterance_branch = layers.MaxPooling1D(pool_size=2)(utterance_branch)\n",
    "utterance_branch = layers.Flatten()(utterance_branch)\n",
    "\n",
    "# Merge both branches\n",
    "merged = layers.Concatenate()([context_branch, utterance_branch])\n",
    "merged = layers.Dense(128, activation=\"relu\")(merged)\n",
    "merged = layers.Dropout(0.3)(merged)  # Dropout to prevent overfitting\n",
    "merged = layers.Dense(64, activation=\"relu\")(merged)\n",
    "merged = layers.Dropout(0.2)(merged)\n",
    "output = layers.Dense(1, activation=\"sigmoid\")(merged)  # Binary classification\n",
    "\n",
    "# Define Model\n",
    "model = keras.Model(inputs=[input_context, input_utterance], outputs=output)\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# Callback to save the best model\n",
    "checkpoint_path = \"best_model.h5\"\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "    checkpoint_path, monitor=\"val_accuracy\", save_best_only=True, mode=\"max\", verbose=1\n",
    ")\n",
    "\n",
    "# Train Model\n",
    "history = model.fit(\n",
    "    [Xc_train, Xu_train], y_train,\n",
    "    epochs=20, batch_size=32,\n",
    "    validation_data=([Xc_test, Xu_test], y_test),\n",
    "    callbacks=[checkpoint]\n",
    ")\n",
    "\n",
    "# Load the best model before making predictions\n",
    "best_model = keras.models.load_model(checkpoint_path)\n",
    "\n",
    "# Predictions using the best model\n",
    "y_train_pred = (best_model.predict([Xc_train, Xu_train]) > 0.5).astype(int)\n",
    "y_test_pred = (best_model.predict([Xc_test, Xu_test]) > 0.5).astype(int)\n",
    "\n",
    "# Print Accuracy\n",
    "train_acc = accuracy_score(y_train, y_train_pred)\n",
    "test_acc = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"\\n‚úÖ Train Accuracy: {train_acc:.4f}\")\n",
    "print(f\"‚úÖ Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "# Find the best epoch and its validation accuracy\n",
    "best_epoch = np.argmax(history.history[\"val_accuracy\"]) + 1\n",
    "best_val_acc = max(history.history[\"val_accuracy\"])\n",
    "\n",
    "print(f\"üèÜ Best Validation Accuracy: {best_val_acc:.4f} at Epoch {best_epoch}\")\n",
    "\n",
    "# Print Classification Reports\n",
    "def format_classification_report(report):\n",
    "    lines = report.split(\"\\n\")\n",
    "    formatted_lines = []\n",
    "    for line in lines:\n",
    "        parts = line.split()\n",
    "        if len(parts) == 5 and parts[0].replace('.', '', 1).isdigit():  # Ensures first part is a number (class label)\n",
    "            formatted_line = f\"{parts[0]:<10} {float(parts[1]):.4f} {float(parts[2]):.4f} {float(parts[3]):.4f} {int(parts[4])}\"\n",
    "            formatted_lines.append(formatted_line)\n",
    "        else:\n",
    "            formatted_lines.append(line)\n",
    "    return \"\\n\".join(formatted_lines)\n",
    "\n",
    "train_report = classification_report(y_train, y_train_pred, digits=4)\n",
    "test_report = classification_report(y_test, y_test_pred, digits=4)\n",
    "\n",
    "print(\"\\nTrain Set Classification Report:\\n\", format_classification_report(train_report))\n",
    "print(\"Test Set Classification Report:\\n\", format_classification_report(test_report))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889d2ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "each branch gets a separate cnn\n",
    "\"\"\"\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load CSV Files\n",
    "df1 = pd.read_csv(\"/content/audio_features_langb.csv\")  # LB dataset\n",
    "df2 = pd.read_csv(\"/content/audio_features_whisper.csv\")  # MMS dataset\n",
    "\n",
    "# Extract Labels (assuming both datasets have the same labels)\n",
    "y = df1[\"Sarcasm\"].values\n",
    "\n",
    "# Extract features from both datasets\n",
    "Xc1 = df1[[col for col in df1.columns if col.startswith(\"audio_c_feature_\")]].values\n",
    "Xu1 = df1[[col for col in df1.columns if col.startswith(\"audio_u_feature_\")]].values\n",
    "Xc2 = df2[[col for col in df2.columns if col.startswith(\"audio_c_feature_\")]].values\n",
    "Xu2 = df2[[col for col in df2.columns if col.startswith(\"audio_u_feature_\")]].values\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "Xc1, Xu1, Xc2, Xu2 = map(lambda x: np.array(x, dtype=np.float32), [Xc1, Xu1, Xc2, Xu2])\n",
    "y = np.array(y, dtype=np.float32)\n",
    "\n",
    "# # Train-test split (70%-30%)\n",
    "# Xc1_train, Xc1_temp, Xu1_train, Xu1_temp, Xc2_train, Xc2_temp, Xu2_train, Xu2_temp, y_train, y_temp = train_test_split(\n",
    "#     Xc1, Xu1, Xc2, Xu2, y, test_size=0.3, random_state=42, stratify=y\n",
    "# )\n",
    "Xc1_train, Xc1_temp, Xu1_train, Xu1_temp, y_train, y_temp = train_test_split(\n",
    "    Xc1, Xu1, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "Xc1_val, Xc1_test, Xu1_val, Xu1_test, y_val, y_test = train_test_split(\n",
    "    Xc1_temp, Xu1_temp, y_temp, test_size=2/3, random_state=42, stratify=y_temp\n",
    ")\n",
    "Xc2_train, Xc2_temp, Xu2_train, Xu2_temp = train_test_split(\n",
    "    Xc2, Xu2, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "Xc2_val, Xc2_test, Xu2_val, Xu2_test = train_test_split(\n",
    "    Xc2_temp, Xu2_temp, test_size=2/3, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "# Further split temp set into validation (10%) and test (20%)\n",
    "Xc1_val, Xc1_test, Xu1_val, Xu1_test, Xc2_val, Xc2_test, Xu2_val, Xu2_test, y_val, y_test = train_test_split(\n",
    "    Xc1_temp, Xu1_temp, Xc2_temp, Xu2_temp, y_temp, test_size=2/3, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "input_dim_lb = Xc1.shape[1]\n",
    "input_dim_mms = Xc2.shape[1]\n",
    "\n",
    "\n",
    "# CNN Model for feature extraction\n",
    "def build_cnn_branch(input_dim):\n",
    "    inp = keras.Input(shape=(input_dim,))\n",
    "    x = layers.Reshape((input_dim, 1))(inp)\n",
    "    x = layers.Conv1D(filters=126, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "    x = layers.Conv1D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    return inp, x\n",
    "\n",
    "# Apply CNN on LB inputs (768)\n",
    "input_c1, context_cnn1 = build_cnn_branch(input_dim_lb)\n",
    "input_u1, utterance_cnn1 = build_cnn_branch(input_dim_lb)\n",
    "\n",
    "# Apply CNN on MMS inputs (1280)\n",
    "input_c2, context_cnn2 = build_cnn_branch(input_dim_mms)\n",
    "input_u2, utterance_cnn2 = build_cnn_branch(input_dim_mms)\n",
    "\n",
    "# First fusion (context_cnn1 + utterance_cnn1) and (context_cnn2 + utterance_cnn2)\n",
    "fused_1 = layers.Concatenate()([context_cnn1, utterance_cnn1])\n",
    "fused_2 = layers.Concatenate()([context_cnn2, utterance_cnn2])\n",
    "\n",
    "# Apply another CNN on fused representations\n",
    "def build_fused_cnn(input_tensor):\n",
    "    x = layers.Reshape((-1, 1))(input_tensor)\n",
    "    x = layers.Conv1D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "    x = layers.Conv1D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    return x\n",
    "\n",
    "def build_fused_fcn(input_tensor):\n",
    "    x = layers.Dense(128, activation=\"swish\")(input_tensor)\n",
    "    x = layers.Dense(64, activation=\"swish\")(x)\n",
    "    x = layers.Dense(32, activation=\"swish\")(x)\n",
    "    return x\n",
    "\n",
    "cnn1 = build_fused_fcn(fused_1)\n",
    "cnn2 = build_fused_fcn(fused_2)\n",
    "\n",
    "# Final fusion (cnn1 + cnn2)\n",
    "final_fusion = layers.Concatenate()([cnn1, cnn2])\n",
    "\n",
    "# Fully connected layers\n",
    "fc = layers.Dense(64, activation=\"swish\")(final_fusion)\n",
    "fc = layers.Dense(32, activation=\"swish\")(fc)\n",
    "output = layers.Dense(1, activation=\"sigmoid\")(fc)\n",
    "\n",
    "# Define and compile model\n",
    "model = keras.Model(inputs=[input_c1, input_u1, input_c2, input_u2], outputs=output)\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "# Model checkpoint\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    \"/kaggle/working/lb+mms_cnn.weights.h5\",\n",
    "    monitor=\"val_accuracy\",\n",
    "    mode=\"max\",\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train Model\n",
    "model.fit(\n",
    "    [Xc1_train, Xu1_train, Xc2_train, Xu2_train], y_train,\n",
    "    epochs=25, batch_size=32,\n",
    "    validation_data=([Xc1_val, Xu1_val, Xc2_val, Xu2_val], y_val),\n",
    "    callbacks=[checkpoint_callback]\n",
    ")\n",
    "\n",
    "# Load best weights\n",
    "model.load_weights(\"/kaggle/working/lb+mms_cnn.weights.h5\")\n",
    "print(\"Loaded Best Model Weights.\")\n",
    "\n",
    "# Predictions\n",
    "y_train_pred = (model.predict([Xc1_train, Xu1_train, Xc2_train, Xu2_train]) > 0.5).astype(int)\n",
    "y_val_pred = (model.predict([Xc1_val, Xu1_val, Xc2_val, Xu2_val]) > 0.5).astype(int)\n",
    "y_test_pred = (model.predict([Xc1_test, Xu1_test, Xc2_test, Xu2_test]) > 0.5).astype(int)\n",
    "\n",
    "# Classification Reports and Accuracy\n",
    "print(\"Train Set Classification Report:\\n\", classification_report(y_train, y_train_pred, digits=4))\n",
    "print(\"Train Accuracy:\", accuracy_score(y_train, y_train_pred))\n",
    "\n",
    "print(\"\\nValidation Set Classification Report:\\n\", classification_report(y_val, y_val_pred, digits=4))\n",
    "print(\"Validation Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
    "\n",
    "print(\"\\nTest Set Classification Report:\\n\", classification_report(y_test, y_test_pred, digits=4))\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cddbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Load CSV Files\n",
    "df1 = pd.read_csv(\"/content/audio_features_langb.csv\")  # LB dataset\n",
    "df2 = pd.read_csv(\"/content/audio_features_whisper.csv\")  # MMS dataset\n",
    "\n",
    "# Extract Labels\n",
    "y = df1[\"Sarcasm\"].values\n",
    "\n",
    "# Extract features from both datasets\n",
    "Xc1 = df1[[col for col in df1.columns if col.startswith(\"audio_c_feature_\")]].values\n",
    "Xu1 = df1[[col for col in df1.columns if col.startswith(\"audio_u_feature_\")]].values\n",
    "Xc2 = df2[[col for col in df2.columns if col.startswith(\"audio_c_feature_\")]].values\n",
    "Xu2 = df2[[col for col in df2.columns if col.startswith(\"audio_u_feature_\")]].values\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "Xc1, Xu1, Xc2, Xu2 = map(lambda x: np.array(x, dtype=np.float32), [Xc1, Xu1, Xc2, Xu2])\n",
    "y = np.array(y, dtype=np.float32)\n",
    "\n",
    "Xc1_train, Xc1_temp, Xu1_train, Xu1_temp, y_train, y_temp = train_test_split(\n",
    "    Xc1, Xu1, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "Xc1_val, Xc1_test, Xu1_val, Xu1_test, y_val, y_test = train_test_split(\n",
    "    Xc1_temp, Xu1_temp, y_temp, test_size=2/3, random_state=42, stratify=y_temp\n",
    ")\n",
    "Xc2_train, Xc2_temp, Xu2_train, Xu2_temp = train_test_split(\n",
    "    Xc2, Xu2, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "Xc2_val, Xc2_test, Xu2_val, Xu2_test = train_test_split(\n",
    "    Xc2_temp, Xu2_temp, test_size=2/3, random_state=42\n",
    ")\n",
    "\n",
    "input_dim_lb = Xc1.shape[1]\n",
    "input_dim_mms = Xc2.shape[1]  # MMS Feature dimension\n",
    "\n",
    "# Fully connected network branch\n",
    "def build_fcn_branch(input_dim):\n",
    "    inp = keras.Input(shape=(input_dim,))\n",
    "    x = layers.Dense(512, activation=\"swish\")(inp)\n",
    "    x = layers.Dense(256, activation=\"swish\")(x)\n",
    "    x = layers.Dense(128, activation=\"swish\")(x)\n",
    "    return inp, x\n",
    "\n",
    "# FCN for LB dataset\n",
    "input_c1, context_fcn1 = build_fcn_branch(input_dim_lb)\n",
    "input_u1, utterance_fcn1 = build_fcn_branch(input_dim_lb)\n",
    "\n",
    "# FCN for MMS dataset\n",
    "input_c2, context_fcn2 = build_fcn_branch(input_dim_mms)\n",
    "input_u2, utterance_fcn2 = build_fcn_branch(input_dim_mms)\n",
    "\n",
    "# First fusion\n",
    "fused_1 = layers.Concatenate()([context_fcn1, utterance_fcn1])\n",
    "fused_2 = layers.Concatenate()([context_fcn2, utterance_fcn2])\n",
    "\n",
    "# Additional FCN model after fusion\n",
    "def build_fcn_model(input_tensor):\n",
    "    x = layers.Dense(512, activation=\"swish\")(input_tensor)\n",
    "    x = layers.Dense(256, activation=\"swish\")(x)\n",
    "    x = layers.Dense(128, activation=\"swish\")(x)\n",
    "    return x\n",
    "\n",
    "fcn1 = build_fcn_model(fused_1)\n",
    "fcn2 = build_fcn_model(fused_2)\n",
    "\n",
    "# Final fusion\n",
    "final_fusion = layers.Concatenate()([fcn1, fcn2])\n",
    "\n",
    "# Fully connected layers\n",
    "fc = layers.Dense(64, activation=\"swish\")(final_fusion)\n",
    "fc = layers.Dense(32, activation=\"swish\")(fc)\n",
    "fc = layers.Dense(8, activation=\"swish\")(fc)\n",
    "output = layers.Dense(1, activation=\"sigmoid\")(fc)\n",
    "\n",
    "# Define and compile model\n",
    "model = keras.Model(inputs=[input_c1, input_u1, input_c2, input_u2], outputs=output)\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "# Model checkpoint\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    \"/kaggle/working/lb+mms_fcn.weights.h5\",\n",
    "    monitor=\"val_accuracy\",\n",
    "    mode=\"max\",\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train Model\n",
    "model.fit(\n",
    "    [Xc1_train, Xu1_train, Xc2_train, Xu2_train], y_train,\n",
    "    epochs=25, batch_size=32,\n",
    "    validation_data=([Xc1_val, Xu1_val, Xc2_val, Xu2_val], y_val),\n",
    "    callbacks=[checkpoint_callback]\n",
    ")\n",
    "\n",
    "# Load best weights\n",
    "model.load_weights(\"/kaggle/working/lb+mms_fcn.weights.h5\")\n",
    "print(\"Loaded Best Model Weights.\")\n",
    "\n",
    "# Predictions\n",
    "y_train_pred = (model.predict([Xc1_train, Xu1_train, Xc2_train, Xu2_train]) > 0.5).astype(int)\n",
    "y_val_pred = (model.predict([Xc1_val, Xu1_val, Xc2_val, Xu2_val]) > 0.5).astype(int)\n",
    "y_test_pred = (model.predict([Xc1_test, Xu1_test, Xc2_test, Xu2_test]) > 0.5).astype(int)\n",
    "\n",
    "# Classification Reports and Accuracy\n",
    "print(\"Train Set Classification Report:\\n\", classification_report(y_train, y_train_pred, digits=4))\n",
    "print(\"Train Accuracy:\", accuracy_score(y_train, y_train_pred))\n",
    "\n",
    "print(\"\\nValidation Set Classification Report:\\n\", classification_report(y_val, y_val_pred, digits=4))\n",
    "print(\"Validation Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
    "\n",
    "print(\"\\nTest Set Classification Report:\\n\", classification_report(y_test, y_test_pred, digits=4))\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddeaf7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sfm_extractor.models.wav2vec2_extractor import Wav2Vec2Extractor\n",
    "\n",
    "# Set parameters\n",
    "input_dir_utterance = \"aditya/audio_utter\"\n",
    "input_dir_context = \"aditya/audio_cont\"\n",
    "output_file_utterance = \"aditya/utterance_features.csv\"\n",
    "output_file_context = \"aditya/context_features.csv\"\n",
    "device = \"cuda\"  # Change to \"cpu\" if no GPU is available\n",
    "\n",
    "# Initialize extractor\n",
    "extractor = Wav2Vec2Extractor(device=device)\n",
    "\n",
    "# Extract features for utterance files\n",
    "print(\"Extracting utterance features...\")\n",
    "extractor.extract_folder(input_dir_utterance, output_file_utterance)\n",
    "\n",
    "# Extract features for context files\n",
    "print(\"Extracting context features...\")\n",
    "extractor.extract_folder(input_dir_context, output_file_context)\n",
    "\n",
    "print(\"Feature extraction completed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
